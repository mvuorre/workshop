[
  {
    "objectID": "modules/censored/index.html",
    "href": "modules/censored/index.html",
    "title": "Censored outcomes",
    "section": "",
    "text": "Code\n# Packages\nlibrary(scales)\nlibrary(knitr)\nlibrary(here)\nlibrary(janitor)\nlibrary(latex2exp)\nlibrary(brms)\nlibrary(distributional)\nlibrary(posterior)\nlibrary(rstan)\nlibrary(patchwork)\nlibrary(tidybayes)\nlibrary(ggdist)\nlibrary(tidyverse)\n\n# Some settings common to all modules\nsource(here(\"modules/_common.R\"))"
  },
  {
    "objectID": "modules/censored/index.html#example-data",
    "href": "modules/censored/index.html#example-data",
    "title": "Censored outcomes",
    "section": "Example data",
    "text": "Example data\nExperiment 1 from Metcalfe et al. (2022):\n\nProcedure. Ninety general information questions (see theonline supplemental material) from Nelson and Narens’ (1980) norms, as updated in Bloom et al. (2018), were presented in a random order. The participant typed in an answer and then made a con dence judgment about the correctness of their answer on a sliding scale from 0% (not at all confident) to 100% (completely confident). They were then given yes/no feedback about the correctness of their answer. If incorrect, they rated their curiosity to find out the correct answer on a sliding scale from 0% (do not care) to 100% (care very much).\n\n\n\nCode\ndat &lt;- read_rds(here(\"data/metcalfe.rds\"))\n\ndat &lt;- dat |&gt; \n  mutate(\n    confidence = confidence / 100,\n    curiosity = curiosity / 100\n  )\n\nhead(dat) |&gt; \n  kable()\n\n\n\n\n\nsubject\nitem\nconfidence\ncuriosity\naccuracy\n\n\n\n\n1\n90\n0.03\nNA\nCorrect\n\n\n1\n10\n0.04\n0.00\nError\n\n\n1\n42\n0.00\nNA\nCorrect\n\n\n1\n20\n0.16\n0.00\nError\n\n\n1\n9\n0.51\n0.74\nError\n\n\n1\n57\n0.00\n0.60\nError\n\n\n\n\n\n\n\nCode\ndat &lt;- dat |&gt; \n  mutate(\n    cl_confidence = case_when(\n      confidence == 0 ~ \"left\",\n      confidence == 1 ~ \"right\",\n      TRUE ~ \"none\"\n    ),\n    cl_curiosity = case_when(\n      curiosity == 0 ~ \"left\",\n      curiosity == 1 ~ \"right\",\n      TRUE ~ \"none\"\n    )\n  )\n\nhead(dat) |&gt; \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsubject\nitem\nconfidence\ncuriosity\naccuracy\ncl_confidence\ncl_curiosity\n\n\n\n\n1\n90\n0.03\nNA\nCorrect\nnone\nnone\n\n\n1\n10\n0.04\n0.00\nError\nnone\nleft\n\n\n1\n42\n0.00\nNA\nCorrect\nleft\nnone\n\n\n1\n20\n0.16\n0.00\nError\nnone\nleft\n\n\n1\n9\n0.51\n0.74\nError\nnone\nnone\n\n\n1\n57\n0.00\n0.60\nError\nleft\nnone\n\n\n\n\n\n\n\nCode\npa &lt;- dat |&gt; \n  ggplot(aes(confidence, fill = accuracy)) +\n  scale_fill_brewer(\n    \"Accuracy\",\n    palette = \"Set1\"\n  ) +\n  geom_histogram(position = \"dodge\")\n\npb &lt;- pa %+% \n  filter(\n    pa$data, \n    subject %in% sample(unique(dat$subject), 9)\n  ) +\n  facet_wrap(\"subject\")\n\n(pa | pb) + \n  plot_layout(guides = \"collect\", axis_titles = \"collect\")"
  },
  {
    "objectID": "modules/censored/index.html#models",
    "href": "modules/censored/index.html#models",
    "title": "Censored outcomes",
    "section": "Models",
    "text": "Models\n\n\nCode\nbf_g &lt;- bf(\n  confidence ~\n    1 + accuracy +\n    (1 + accuracy | subject) \n) +\n  gaussian()\n\nfitg &lt;- brm(\n  bf_g,\n  data = dat,\n  control = list(adapt_delta = .95),\n  file = here(\"models/censored-0\")\n)\n\n\n\n\nCode\nbf_c &lt;- bf(\n  confidence | cens(cl_confidence) ~\n    1 + accuracy +\n    (1 + accuracy | subject) \n) +\n  gaussian()\n\nfitc &lt;- brm(\n  bf_c,\n  data = dat,\n  control = list(adapt_delta = .95),\n  file = here(\"models/censored-1\")\n)"
  },
  {
    "objectID": "modules/censored/index.html#summary",
    "href": "modules/censored/index.html#summary",
    "title": "Censored outcomes",
    "section": "Summary",
    "text": "Summary\n\n\nCode\nsummary(fitg)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: confidence ~ 1 + accuracy + (1 + accuracy | subject) \n#&gt;    Data: dat (Number of observations: 3873) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Multilevel Hyperparameters:\n#&gt; ~subject (Number of levels: 44) \n#&gt;                                Estimate Est.Error l-95% CI u-95% CI Rhat\n#&gt; sd(Intercept)                      0.11      0.01     0.09     0.14 1.00\n#&gt; sd(accuracyCorrect)                0.08      0.01     0.05     0.11 1.00\n#&gt; cor(Intercept,accuracyCorrect)    -0.14      0.20    -0.52     0.26 1.00\n#&gt;                                Bulk_ESS Tail_ESS\n#&gt; sd(Intercept)                      1212     1677\n#&gt; sd(accuracyCorrect)                1808     2696\n#&gt; cor(Intercept,accuracyCorrect)     2492     2954\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept           0.22      0.02     0.19     0.26 1.01      812     1553\n#&gt; accuracyCorrect     0.50      0.01     0.47     0.53 1.00     2807     2650\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     0.27      0.00     0.26     0.28 1.00     7919     2660\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\nsummary(fitc)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: confidence | cens(cl_confidence) ~ 1 + accuracy + (1 + accuracy | subject) \n#&gt;    Data: dat (Number of observations: 3873) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Multilevel Hyperparameters:\n#&gt; ~subject (Number of levels: 44) \n#&gt;                                Estimate Est.Error l-95% CI u-95% CI Rhat\n#&gt; sd(Intercept)                      0.20      0.02     0.16     0.25 1.00\n#&gt; sd(accuracyCorrect)                0.18      0.03     0.13     0.24 1.00\n#&gt; cor(Intercept,accuracyCorrect)    -0.38      0.16    -0.65    -0.04 1.01\n#&gt;                                Bulk_ESS Tail_ESS\n#&gt; sd(Intercept)                       975     1640\n#&gt; sd(accuracyCorrect)                1366     2514\n#&gt; cor(Intercept,accuracyCorrect)     1430     2392\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept           0.10      0.03     0.04     0.17 1.01      541     1096\n#&gt; accuracyCorrect     0.71      0.03     0.65     0.77 1.00     1445     2633\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     0.40      0.01     0.39     0.41 1.00     8960     2909\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "modules/censored/index.html#model-comparison",
    "href": "modules/censored/index.html#model-comparison",
    "title": "Censored outcomes",
    "section": "Model comparison",
    "text": "Model comparison\n\n\nCode\n# Add LOO criteria to all models\nfitg &lt;- add_criterion(fitg, \"loo\")\nfitc &lt;- add_criterion(fitc, \"loo\")\n\n\n\n\nCode\nloo_compare(\n  fitc, fitg\n)\n#&gt;      elpd_diff se_diff\n#&gt; fitg     0.0       0.0\n#&gt; fitc -1918.1      25.8\n\n\n\nWhat is happening?"
  },
  {
    "objectID": "modules/ordinal/index.html",
    "href": "modules/ordinal/index.html",
    "title": "Ordinal Models",
    "section": "",
    "text": "Figure 1: A mood item\n\n\n\n\nOrdinal data are common in psychology\nMost common are Likert items\nBut also e.g. item above; school grades; number of forks you own; discrete temporal data\n\n\n\n\n\nMetric models\n\nModels that assume outcomes have a continuous distribution, e.g. t-test\nOverestimate information in data; common & “simple”\n\nNonparametric statistics\n\ne.g. analyses of signed ranks (R: ?wilcox.test, etc.)\nUnderestimate information in data; don’t scale well\n\nOrdinal models\n\nA zoo of models that treat outcomes appropriately as ordered categories\nLet’s learn more!\n“Ordinal Regression Models in Psychology: A Tutorial” (Bürkner and Vuorre 2019)\n\n\n\n\n\n\nLiddell and Kruschke surveyed 68 Psychology articles that analysed ordinal data, and found that every article used metric models (2018)\nMetric models on ordinal data can lead to false alarms, failures to detect true effects, distorted effect size estimates, and inversions of effects\nThree main shortcomings of metric models:\n\nResponse categories may not be (e.g. psychologically) equidistant\nResponses can be non-normally distributed\nCan treat differences in variances of underlying variable inappropriately\n\nI don’t mean to be an alarmist, or ignore practical considerations. We don’t know the empirical rate of differences. But…\n\n\n\n\n\n\nCode\nmovies &lt;- read_rds(here(\"data/movie-data.rds\"))\nmovies510 &lt;- filter(movies, movie %in% c(5, 10))\nmovies510 &lt;- pivot_longer(\n  movies510,\n  cols = -c(movie, title),\n  names_to = \"Rating\",\n  names_transform = ~str_remove(.x, \"n\") |&gt; as.integer(),\n  values_to = \"Count\"\n) |&gt;\n  uncount(Count)\nmovies510 |&gt;\n  ggplot(aes(Rating)) +\n  geom_histogram(binwidth = .5, center = 0) +\n  scale_y_continuous(expand = expansion(c(0, .1))) +\n  facet_wrap(\"movie\", nrow = 1, labeller = label_both)\n\n\n\n\n\n\n\n\nFigure 2: IMDB ratings of two movies.\n\n\n\n\n\n\n\nCode\ny &lt;- t.test(scale(Rating) ~ movie, data = movies510)\ny &lt;- tidy(y)\n# Reverse because t-test subtracts latter level from former\ny &lt;- mutate(y, across(where(is.numeric), ~ -round(., 2)))\n\ny2 &lt;- clm(\n  ordered(Rating) ~ movie,\n  ~movie,\n  link = \"probit\",\n  data = movies510\n)\ny2 &lt;- tidy(y2, conf.int = TRUE)[5, ]\ny2 &lt;- mutate(y2, across(where(is.numeric), ~ round(., 2)))\n\n\n\nWelch’s t-test: Movie 10’s mean rating was significantly greater (Standardized difference = 0.14 [0.23, 0.04])\nCumulative probit model: Movie 10’s mean rating was significantly smaller (Difference = -0.2 [-0.31, -0.09])\nI cherry-picked this example but it exists"
  },
  {
    "objectID": "modules/ordinal/index.html#what-are-ordinal-data",
    "href": "modules/ordinal/index.html#what-are-ordinal-data",
    "title": "Ordinal Models",
    "section": "",
    "text": "Figure 1: A mood item\n\n\n\n\nOrdinal data are common in psychology\nMost common are Likert items\nBut also e.g. item above; school grades; number of forks you own; discrete temporal data"
  },
  {
    "objectID": "modules/ordinal/index.html#methods-for-analysis",
    "href": "modules/ordinal/index.html#methods-for-analysis",
    "title": "Ordinal Models",
    "section": "",
    "text": "Metric models\n\nModels that assume outcomes have a continuous distribution, e.g. t-test\nOverestimate information in data; common & “simple”\n\nNonparametric statistics\n\ne.g. analyses of signed ranks (R: ?wilcox.test, etc.)\nUnderestimate information in data; don’t scale well\n\nOrdinal models\n\nA zoo of models that treat outcomes appropriately as ordered categories\nLet’s learn more!\n“Ordinal Regression Models in Psychology: A Tutorial” (Bürkner and Vuorre 2019)"
  },
  {
    "objectID": "modules/ordinal/index.html#analyzing-ordinal-data-with-metric-models-what-could-possibly-go-wrong",
    "href": "modules/ordinal/index.html#analyzing-ordinal-data-with-metric-models-what-could-possibly-go-wrong",
    "title": "Ordinal Models",
    "section": "",
    "text": "Liddell and Kruschke surveyed 68 Psychology articles that analysed ordinal data, and found that every article used metric models (2018)\nMetric models on ordinal data can lead to false alarms, failures to detect true effects, distorted effect size estimates, and inversions of effects\nThree main shortcomings of metric models:\n\nResponse categories may not be (e.g. psychologically) equidistant\nResponses can be non-normally distributed\nCan treat differences in variances of underlying variable inappropriately\n\nI don’t mean to be an alarmist, or ignore practical considerations. We don’t know the empirical rate of differences. But…"
  },
  {
    "objectID": "modules/ordinal/index.html#analyzing-ordinal-data-with-metric-models-what-could-possibly-go-wrong-1",
    "href": "modules/ordinal/index.html#analyzing-ordinal-data-with-metric-models-what-could-possibly-go-wrong-1",
    "title": "Ordinal Models",
    "section": "",
    "text": "Code\nmovies &lt;- read_rds(here(\"data/movie-data.rds\"))\nmovies510 &lt;- filter(movies, movie %in% c(5, 10))\nmovies510 &lt;- pivot_longer(\n  movies510,\n  cols = -c(movie, title),\n  names_to = \"Rating\",\n  names_transform = ~str_remove(.x, \"n\") |&gt; as.integer(),\n  values_to = \"Count\"\n) |&gt;\n  uncount(Count)\nmovies510 |&gt;\n  ggplot(aes(Rating)) +\n  geom_histogram(binwidth = .5, center = 0) +\n  scale_y_continuous(expand = expansion(c(0, .1))) +\n  facet_wrap(\"movie\", nrow = 1, labeller = label_both)\n\n\n\n\n\n\n\n\nFigure 2: IMDB ratings of two movies.\n\n\n\n\n\n\n\nCode\ny &lt;- t.test(scale(Rating) ~ movie, data = movies510)\ny &lt;- tidy(y)\n# Reverse because t-test subtracts latter level from former\ny &lt;- mutate(y, across(where(is.numeric), ~ -round(., 2)))\n\ny2 &lt;- clm(\n  ordered(Rating) ~ movie,\n  ~movie,\n  link = \"probit\",\n  data = movies510\n)\ny2 &lt;- tidy(y2, conf.int = TRUE)[5, ]\ny2 &lt;- mutate(y2, across(where(is.numeric), ~ round(., 2)))\n\n\n\nWelch’s t-test: Movie 10’s mean rating was significantly greater (Standardized difference = 0.14 [0.23, 0.04])\nCumulative probit model: Movie 10’s mean rating was significantly smaller (Difference = -0.2 [-0.31, -0.09])\nI cherry-picked this example but it exists"
  },
  {
    "objectID": "modules/ordinal/index.html#ordinal-models",
    "href": "modules/ordinal/index.html#ordinal-models",
    "title": "Ordinal Models",
    "section": "Ordinal models",
    "text": "Ordinal models\n\nThere are many different ordinal models\nWe focus on the cumulative model (CM)\n\nGenerally the most useful / widely applicable model\n\nIRT? SDT?\n\nAlso known as graded response model, SDT model for ratings, etc…"
  },
  {
    "objectID": "modules/ordinal/index.html#example-data",
    "href": "modules/ordinal/index.html#example-data",
    "title": "Ordinal Models",
    "section": "Example data",
    "text": "Example data\n\nWe introduce CM in the context of a study conducted by (Forstmann et al. 2020)\n\n\n\nCode\ndat &lt;- read_rds(here(\"data/forstmann.rds\"))\n\n\n\n1,225 festivalgoers were asked about their mood, substance use, degree of experiencing a “transformative experience”\nThe mood rating item, \\(Y\\), had \\(K + 1 = 6\\) categories \\(1, 2, ..., 6\\)\n\n\n\nCode\nhead(dat) |&gt;\n  kable()\n\n\n\n\n\n\n\n\nmood\nte\ngender\nage\nsurvey\nh24\n\n\n\n\n5\n3\n1\n30\nEvent3\n0\n\n\n5\n2\n2\n50\nEvent5\n0\n\n\n6\n7\n1\n32\nEvent4\n0\n\n\n6\n7\n2\n33\nEvent2\n0\n\n\n5\n1\n1\n22\nEvent3\n0\n\n\n5\n7\n2\n22\nEvent4\n0\n\n\n\n\n\n\nTable 1: First six rows of data from Forstmann et al. (2020)."
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-1",
    "href": "modules/ordinal/index.html#cumulative-model-1",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCM assumes that the observed categorical variable \\(Y\\) is based on the categorization of an unobserved (“latent”) variable \\(\\tilde{Y}\\) with \\(K\\) thresholds \\(\\tau = (\\tau_1, \\dots, \\tau_k)\\).\nIn this example, \\(\\tilde{Y}\\) has a natural interpretation as current mood\nWe assume that \\(\\tilde{Y}\\) has a normal distribution, but other choices are possible, such as (default) logistic\nDescribe the ordered distribution of responses using thresholds\n\n\\(Y = k \\Leftrightarrow \\tau_{k-1} &lt; \\tilde{Y} \\leq \\tau_k\\)\n\nThese thresholds give the probability of each response category\n\n\\(Pr(Y = k) = \\Phi(\\tau_k) - \\Phi(\\tau_{k-1})\\)\n\n\\(\\tilde{Y}\\) is amenable to regression (without intercept)\n\n\\(\\tilde{Y} \\sim N(\\eta, \\sigma = 1); \\ \\eta = b_1x_1 +...\\)\n\\(Pr(Y = k \\vert \\eta) = \\Phi(\\tau_k - \\eta) - \\Phi(\\tau_{k-1} - \\eta)\\)"
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-2",
    "href": "modules/ordinal/index.html#cumulative-model-2",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\ntab &lt;- count(dat, mood, name = \"Count\") |&gt;\n  mutate(\n    p = Count / sum(Count),\n    cp = cumsum(p),\n    z = qnorm(cp)\n  )\n\np0 &lt;- tab |&gt;\n  ggplot(aes(mood)) +\n  geom_col(aes(y = Count)) +\n  labs(x = \"Mood\") +\n  scale_y_continuous(expand = expansion(c(0, .1)))\np0\n\n\n\n\n\n\n\n\nFigure 3: Counts of responses in six mood categories."
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-3",
    "href": "modules/ordinal/index.html#cumulative-model-3",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\nx &lt;- tidy(ordinal::clm(ordered(mood) ~ 1, link = \"probit\", data = dat))\nthresholds &lt;- pull(x, estimate)\nx &lt;- tibble(\n  x = seq(-4, 4, by = .01),\n  y = dnorm(x)\n)\n\np1 &lt;- x |&gt;\n  ggplot(aes(x, y)) +\n  geom_line(size = 1) +\n  scale_y_continuous(expand = expansion(c(0, .3))) +\n  scale_x_continuous(\n    expression(tilde(Y))\n  ) +\n  theme(\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank()\n  )\np1\n\n\n\n\n\n\n\n\nFigure 4: Distribution of latent normal mood."
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-4",
    "href": "modules/ordinal/index.html#cumulative-model-4",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\np1 +\n  scale_x_continuous(\n    expression(tilde(Y)),\n    breaks = thresholds,\n    labels = c(expression(tau[1]), ~ tau[2], ~ tau[3], ~ tau[4], ~ tau[5])\n  ) +\n  geom_vline(xintercept = thresholds, size = .25)\n\n\n\n\n\n\n\n\nFigure 5: Distribution of latent normal mood with estimated thresholds."
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-5",
    "href": "modules/ordinal/index.html#cumulative-model-5",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\ntab &lt;- count(dat, mood) |&gt;\n  mutate(\n    p = n / sum(n),\n    cp = cumsum(p),\n    z = qnorm(cp)\n  )\n\n\n\n\nCode\nkable(tab, digits = 2)\n\n\n\n\n\n\n\n\nmood\nn\np\ncp\nz\n\n\n\n\n1\n5\n0.00\n0.00\n-2.63\n\n\n2\n10\n0.01\n0.01\n-2.23\n\n\n3\n23\n0.02\n0.03\n-1.84\n\n\n4\n151\n0.13\n0.16\n-0.98\n\n\n5\n661\n0.57\n0.73\n0.62\n\n\n6\n310\n0.27\n1.00\nInf\n\n\n\n\n\n\nTable 2: Calculating thresholds by hand."
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-6",
    "href": "modules/ordinal/index.html#cumulative-model-6",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\ntab &lt;- count(dat, mood) |&gt;\n  mutate(\n    p = n / sum(n),\n    cp = cumsum(p),\n    z = qnorm(cp)\n  )\n\n\n\n\nCode\np2 &lt;- tab |&gt;\n  ggplot(aes(mood, cp)) +\n  geom_line() +\n  xlab(\"Mood\") +\n  geom_point(shape = 21, fill = \"white\")\np3 &lt;- tab[-6, ] |&gt;\n  ggplot(aes(mood, z)) +\n  geom_line() +\n  xlab(\"Threshold\") +\n  geom_point(shape = 21, fill = \"white\")\n(p0 | p2 | p3) +\n  scale_x_continuous(breaks = 1:6)\n\n\n\n\n\n\n\n\nFigure 6: Illustration of how thresholds are calculated from data."
  },
  {
    "objectID": "modules/ordinal/index.html#in-practice",
    "href": "modules/ordinal/index.html#in-practice",
    "title": "Ordinal Models",
    "section": "In practice",
    "text": "In practice\n\n\nCode\nlibrary(brms) # Bayesian, slower, more flexible\nlibrary(ordinal) # Frequentist, fast, less flexible\n\n\n\nSo far we have described a weird link function + intercepts\nWrite your regressions in R (brms) modelling syntax\nEffects on \\(\\tilde{Y}\\) are directly interpretable"
  },
  {
    "objectID": "modules/ordinal/index.html#my-first-cumulative-model",
    "href": "modules/ordinal/index.html#my-first-cumulative-model",
    "title": "Ordinal Models",
    "section": "My first cumulative model",
    "text": "My first cumulative model\n\n\nCode\ndat &lt;- mutate(\n  dat, \n  h24 = factor(h24, labels = c(\"No\", \"Yes\"))\n)\nfit1 &lt;- brm(\n  mood ~ h24,\n  family = cumulative(\"probit\"),\n  data = dat,\n  file = here(\"models/ordinal-1\")\n)\n\n\n\nfamily = cumulative(): CM\n\"probit\": \\(\\tilde{Y} \\sim {N}(\\eta, \\sigma = 1)\\)\nmood ~ h24: \\(\\eta = b_1\\text{h24}\\)\n\\(b_1\\) is the degree to which mood is greater in people who used hallucinogens in the past 24 hours, compared to people who didn’t use\nScale of the latent variable (standard deviations)"
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-7",
    "href": "modules/ordinal/index.html#cumulative-model-7",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\nsummary(fit1)\n#&gt;  Family: cumulative \n#&gt;   Links: mu = probit; disc = identity \n#&gt; Formula: mood ~ h24 \n#&gt;    Data: dat (Number of observations: 1160) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept[1]    -2.63      0.15    -2.95    -2.34 1.00     2324     2419\n#&gt; Intercept[2]    -2.20      0.10    -2.40    -2.01 1.00     3627     3111\n#&gt; Intercept[3]    -1.80      0.07    -1.94    -1.66 1.00     4202     2939\n#&gt; Intercept[4]    -0.93      0.05    -1.02    -0.84 1.00     3977     3305\n#&gt; Intercept[5]     0.69      0.04     0.61     0.77 1.00     3898     3065\n#&gt; h24Yes           0.39      0.09     0.21     0.56 1.00     4301     2504\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; disc     1.00      0.00     1.00     1.00   NA       NA       NA\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-8",
    "href": "modules/ordinal/index.html#cumulative-model-8",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\nplot(fit1, pars = \"b_\", N = 6)"
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-9",
    "href": "modules/ordinal/index.html#cumulative-model-9",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\nthresholds &lt;- fixef(fit1)[1:5, 1]\nbeta1 &lt;- fixef(fit1)[6, 1]\nx &lt;- tibble(\n  x = seq(-4, 4, by = .01),\n  No = dnorm(x),\n  Yes = dnorm(x, beta1)\n)\nx |&gt;\n  pivot_longer(c(No, Yes), names_to = \"h24\") |&gt;\n  ggplot(aes(x, value, col = h24)) +\n  geom_vline(xintercept = thresholds, size = .25) +\n  geom_line(size = 1) +\n  scale_color_brewer(\n    \"Hallucinogens past 24 hours\",\n    palette = \"Set1\"\n  ) +\n  scale_y_continuous(expand = expansion(c(0, .3))) +\n  scale_x_continuous(\n    expression(tilde(Y)),\n    breaks = thresholds,\n    labels = c(expression(tau[1]), ~ tau[2], ~ tau[3], ~ tau[4], ~ tau[5])\n  ) +\n  theme(\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank()\n  )"
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-10",
    "href": "modules/ordinal/index.html#cumulative-model-10",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\nconditional_effects(fit1, categorical = TRUE)"
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-11",
    "href": "modules/ordinal/index.html#cumulative-model-11",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\npp_check(fit1, \"bars_grouped\", group = \"h24\")"
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-12",
    "href": "modules/ordinal/index.html#cumulative-model-12",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\nIt is considered SOP to not assume equal variances when we do e.g. t tests\nMetric models can deal terribly with different variances in \\(\\tilde{Y}\\)\nWe can predict the variance (without intercept–must be fixed for baseline)\n\\(Pr(Y = k \\vert \\eta, disc) = \\Phi(disc \\times (\\tau_{k+1} - \\eta)) - \\Phi(disc \\times (\\tau_{k} - \\eta))\\)\ndisc?\n\nIRT: Discrimination parameter (slope of response function)\nPredicted on the log scale \\(disc = exp(\\eta_{disc})\\)\n\\(\\sigma\\) = \\(1 / exp(disc)\\)\n\n\\(\\tilde{Y} \\sim N(\\eta, 1/exp(\\eta_{disc})); \\ \\eta = b_1x_1 +...; \\eta_{disc} = g_1x_2 + ...\\)"
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-13",
    "href": "modules/ordinal/index.html#cumulative-model-13",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\nfit2 &lt;- brm(\n  bf(mood ~ h24) +\n    lf(disc ~ 0 + h24, cmc = FALSE),\n  family = cumulative(\"probit\"),\n  data = dat,\n  file = here(\"models/ordinal-2\")\n)"
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-14",
    "href": "modules/ordinal/index.html#cumulative-model-14",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\nsummary(fit2)\n#&gt;  Family: cumulative \n#&gt;   Links: mu = probit; disc = log \n#&gt; Formula: mood ~ h24 \n#&gt;          disc ~ 0 + h24\n#&gt;    Data: dat (Number of observations: 1160) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept[1]    -2.62      0.16    -2.95    -2.33 1.00     2586     2250\n#&gt; Intercept[2]    -2.18      0.10    -2.40    -1.99 1.00     3440     2578\n#&gt; Intercept[3]    -1.78      0.07    -1.93    -1.64 1.00     4079     2950\n#&gt; Intercept[4]    -0.92      0.05    -1.01    -0.82 1.00     4161     3300\n#&gt; Intercept[5]     0.68      0.04     0.60     0.77 1.00     3863     3198\n#&gt; h24Yes           0.37      0.09     0.20     0.55 1.00     4322     2518\n#&gt; disc_h24Yes      0.08      0.08    -0.08     0.24 1.00     3838     3084\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-15",
    "href": "modules/ordinal/index.html#cumulative-model-15",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\nas_draws_df(fit2, variable = \"h24\", regex = TRUE) |&gt;\n  mutate(sigma_h24 = 1 / exp(b_disc_h24Yes)) |&gt;\n  pivot_longer(contains(\"h24\")) |&gt;\n  ggplot(aes(value, name)) +\n  stat_histinterval()"
  },
  {
    "objectID": "modules/ordinal/index.html#cumulative-model-16",
    "href": "modules/ordinal/index.html#cumulative-model-16",
    "title": "Ordinal Models",
    "section": "Cumulative model",
    "text": "Cumulative model\n\n\nCode\nthresholds &lt;- fixef(fit2)[1:5, 1]\nbeta1 &lt;- fixef(fit2)[6, 1]\ndisc1 &lt;- 1 / exp(fixef(fit2)[7, 1])\nx &lt;- tibble(\n  x = seq(-4, 4, by = .01),\n  No = dnorm(x),\n  Yes = dnorm(x, beta1, disc1)\n)\nx |&gt;\n  pivot_longer(c(No, Yes), names_to = \"h24\") |&gt;\n  ggplot(aes(x, value, col = h24)) +\n  geom_vline(xintercept = thresholds, size = .25) +\n  geom_line(size = 1) +\n  scale_y_continuous(expand = expansion(c(0, .3))) +\n  scale_x_continuous(\n    expression(tilde(Y)),\n    breaks = thresholds,\n    labels = c(expression(tau[1]), ~ tau[2], ~ tau[3], ~ tau[4], ~ tau[5])\n  ) +\n  theme(\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank()\n  )"
  },
  {
    "objectID": "modules/ordinal/index.html#category-specific-effects",
    "href": "modules/ordinal/index.html#category-specific-effects",
    "title": "Ordinal Models",
    "section": "Category specific effects",
    "text": "Category specific effects\n\nCannot use CM*\nAdjacent category model: predict decisions between categories\n\n\n\n\n\n\n\nFigure 7: Adjacent category model."
  },
  {
    "objectID": "modules/ordinal/index.html#category-specific-effects-1",
    "href": "modules/ordinal/index.html#category-specific-effects-1",
    "title": "Ordinal Models",
    "section": "Category specific effects",
    "text": "Category specific effects\n\nThere are two cells with no observations\n\n\n\nCode\ntable(dat$h24, dat$mood)\n#&gt;      \n#&gt;         1   2   3   4   5   6\n#&gt;   No    5  10  22 136 561 242\n#&gt;   Yes   0   0   1  15 100  68\n\n\n\nThose category-specific effects won’t be identified\nIf only there was a way to inject information to the model…\nBayes to the rescue!\n\n\n\nCode\nweakly_informative_prior &lt;- prior(normal(0, 1.5), class = \"b\")\nfit3 &lt;- brm(\n  bf(mood ~ cs(h24)),\n  family = acat(\"probit\"),\n  prior = weakly_informative_prior,\n  data = dat,\n  control = list(adapt_delta = .95),\n  file = here(\"models/ordinal-3\")\n)"
  },
  {
    "objectID": "modules/ordinal/index.html#category-specific-effects-2",
    "href": "modules/ordinal/index.html#category-specific-effects-2",
    "title": "Ordinal Models",
    "section": "Category specific effects",
    "text": "Category specific effects\n\n\nCode\nsummary(fit3)\n#&gt;  Family: acat \n#&gt;   Links: mu = probit; disc = identity \n#&gt; Formula: mood ~ cs(h24) \n#&gt;    Data: dat (Number of observations: 1160) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept[1]    -0.44      0.34    -1.11     0.20 1.00     3732     2856\n#&gt; Intercept[2]    -0.52      0.23    -0.97    -0.08 1.00     3159     2726\n#&gt; Intercept[3]    -1.09      0.12    -1.33    -0.84 1.00     3142     2779\n#&gt; Intercept[4]    -0.86      0.06    -0.97    -0.75 1.00     3525     2854\n#&gt; Intercept[5]     0.52      0.05     0.43     0.61 1.00     3997     3026\n#&gt; h24Yes[1]        0.38      1.28    -2.00     3.02 1.00     4609     2614\n#&gt; h24Yes[2]        1.05      1.13    -0.98     3.45 1.00     4261     3092\n#&gt; h24Yes[3]        0.61      0.51    -0.29     1.70 1.00     4065     2661\n#&gt; h24Yes[4]        0.28      0.16    -0.02     0.60 1.00     3709     2692\n#&gt; h24Yes[5]        0.28      0.11     0.06     0.49 1.00     4091     3115\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; disc     1.00      0.00     1.00     1.00   NA       NA       NA\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "modules/ordinal/index.html#category-specific-effects-3",
    "href": "modules/ordinal/index.html#category-specific-effects-3",
    "title": "Ordinal Models",
    "section": "Category specific effects",
    "text": "Category specific effects\n\n\nCode\nconditional_effects(fit3, categorical = TRUE)"
  },
  {
    "objectID": "modules/ordinal/index.html#category-specific-effects-4",
    "href": "modules/ordinal/index.html#category-specific-effects-4",
    "title": "Ordinal Models",
    "section": "Category specific effects",
    "text": "Category specific effects\n\n\nCode\nx &lt;- conditional_effects(fit1, categorical = TRUE)[[1]]\np1 &lt;- x |&gt;\n  ggplot(aes(cats__, estimate__, col = h24)) +\n  geom_pointrange(\n    aes(ymin = lower__, ymax = upper__),\n    position = position_dodge(.25)\n  ) +\n  labs(\n    subtitle = \"Cumulative model\",\n    x = \"Response category (mood)\",\n    y = \"Probability\"\n  )\nx &lt;- conditional_effects(fit3, categorical = TRUE)[[1]]\np2 &lt;- x |&gt;\n  ggplot(aes(cats__, estimate__, col = h24)) +\n  geom_pointrange(\n    aes(ymin = lower__, ymax = upper__),\n    position = position_dodge(.25)\n  ) +\n  labs(\n    subtitle = \"Adjacent category model (CS)\",\n    x = \"Response category (mood)\",\n    y = \"Probability\"\n  )\n(p1 | p2) + plot_layout(guides = \"collect\")"
  },
  {
    "objectID": "modules/ordinal/index.html#model-comparison",
    "href": "modules/ordinal/index.html#model-comparison",
    "title": "Ordinal Models",
    "section": "Model comparison",
    "text": "Model comparison\n\n\nCode\nfit4 &lt;- brm(\n  bf(mood ~ h24),\n  family = acat(\"probit\"),\n  prior = weakly_informative_prior,\n  data = dat,\n  file = here(\"models/ordinal-4\")\n)\n\n# Add LOO criteria to all models\nfit1 &lt;- add_criterion(fit1, \"loo\")\nfit2 &lt;- add_criterion(fit2, \"loo\")\nfit3 &lt;- add_criterion(fit3, \"loo\")\nfit4 &lt;- add_criterion(fit4, \"loo\")\n\n\n\n\nCode\nloo_compare(\n  fit1, fit2, fit3, fit4\n)\n#&gt;      elpd_diff se_diff\n#&gt; fit4  0.0       0.0   \n#&gt; fit1 -0.7       0.6   \n#&gt; fit2 -1.2       0.5   \n#&gt; fit3 -2.9       2.1"
  },
  {
    "objectID": "modules/ordinal/index.html#its-too-difficult",
    "href": "modules/ordinal/index.html#its-too-difficult",
    "title": "Ordinal Models",
    "section": "Its too difficult",
    "text": "Its too difficult\n\n…\nThere are, of course, practical considerations\nThe weird link function and intercepts were difficult\nEffects on latent variable are interpretable just like your betas in lm()"
  },
  {
    "objectID": "modules/ordinal/index.html#the-results-are-the-same-anyway",
    "href": "modules/ordinal/index.html#the-results-are-the-same-anyway",
    "title": "Ordinal Models",
    "section": "The results are the same anyway",
    "text": "The results are the same anyway\n\nHow do you know?\nDid you fit an ordinal model to confirm?\nThe prevalence of problems in metric models applied to ordinal data is an empirical questions, and results probably vary greatly between types of data & measures\nFit ordinal models whenever you can\nAfford more nuanced interpretation of what’s going on in your data"
  },
  {
    "objectID": "modules/ordinal/index.html#so-far",
    "href": "modules/ordinal/index.html#so-far",
    "title": "Ordinal Models",
    "section": "So far…",
    "text": "So far…\n\nWe did not consider variability in mood beyond hallucinogen use\nModeled H as fixed effect\nAge? Survey (different events)? Interactions??\nMultilevel model is a kind of interaction model"
  },
  {
    "objectID": "modules/ordinal/index.html#multilevel-model-1",
    "href": "modules/ordinal/index.html#multilevel-model-1",
    "title": "Ordinal Models",
    "section": "Multilevel model",
    "text": "Multilevel model\n\n\nCode\nfit5 &lt;- brm(\n  bf(mood ~ h24 + (h24 | survey)),\n  family = cumulative(\"probit\"),\n  data = dat,\n  file = here(\"models/ordinal-5\")\n)"
  },
  {
    "objectID": "modules/ordinal/index.html#events",
    "href": "modules/ordinal/index.html#events",
    "title": "Ordinal Models",
    "section": "Events",
    "text": "Events\n\n\nCode\nsummary(fit5)\n#&gt;  Family: cumulative \n#&gt;   Links: mu = probit; disc = identity \n#&gt; Formula: mood ~ h24 + (h24 | survey) \n#&gt;    Data: dat (Number of observations: 1160) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Multilevel Hyperparameters:\n#&gt; ~survey (Number of levels: 6) \n#&gt;                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sd(Intercept)           0.30      0.20     0.03     0.81 1.00      942      738\n#&gt; sd(h241)                0.33      0.28     0.01     1.06 1.00      966     1466\n#&gt; cor(Intercept,h241)    -0.08      0.57    -0.96     0.92 1.00     2555     2615\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept[1]    -2.87      0.23    -3.30    -2.41 1.00     2176     1990\n#&gt; Intercept[2]    -2.41      0.19    -2.76    -2.02 1.00     2076     2064\n#&gt; Intercept[3]    -1.98      0.17    -2.30    -1.59 1.00     1913     2104\n#&gt; Intercept[4]    -1.08      0.16    -1.37    -0.71 1.00     1758     1960\n#&gt; Intercept[5]     0.57      0.16     0.29     0.94 1.00     1729     1936\n#&gt; h241             0.33      0.22    -0.09     0.84 1.00     1347     1144\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; disc     1.00      0.00     1.00     1.00   NA       NA       NA\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "modules/ordinal/index.html#another-way-to-vary-intercepts",
    "href": "modules/ordinal/index.html#another-way-to-vary-intercepts",
    "title": "Ordinal Models",
    "section": "Another way to vary intercepts",
    "text": "Another way to vary intercepts\nThis is not a great idea but in theory works.\n\n\nCode\nfit6 &lt;- brm(\n  bf(mood | resp_thres(gr = survey) ~ h24 + (0 + h24 | survey)),\n  family = cumulative(\"probit\"),\n  data = dat,\n  file = here(\"models/ordinal-6\")\n)\n\n\n\n\nCode\nsummary(fit6)\n#&gt;  Family: cumulative \n#&gt;   Links: mu = probit; disc = identity \n#&gt; Formula: mood | resp_thres(gr = survey) ~ h24 + (0 + h24 | survey) \n#&gt;    Data: dat (Number of observations: 1160) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Multilevel Hyperparameters:\n#&gt; ~survey (Number of levels: 6) \n#&gt;                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sd(h24No)             0.89      0.73     0.03     2.69 1.01      709     1618\n#&gt; sd(h24Yes)            1.11      0.89     0.04     3.21 1.00      686     1809\n#&gt; cor(h24No,h24Yes)     0.55      0.52    -0.80     1.00 1.00     1218     1918\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept[Event1,1]    -6.00      3.61   -15.40    -1.66 1.01     1367     1040\n#&gt; Intercept[Event1,2]    -3.31      1.73    -7.23    -0.63 1.00     1536     1660\n#&gt; Intercept[Event1,3]    -1.20      0.92    -2.61     0.91 1.00     1224     3040\n#&gt; Intercept[Event1,4]    -0.39      0.91    -1.75     1.74 1.00     1223     3260\n#&gt; Intercept[Event1,5]     1.14      0.91    -0.24     3.29 1.00     1214     3155\n#&gt; Intercept[Event2,1]    -5.02      2.92   -13.13    -1.41 1.00     1151      959\n#&gt; Intercept[Event2,2]    -1.87      0.82    -3.14     0.03 1.00     1188     3161\n#&gt; Intercept[Event2,3]    -1.48      0.81    -2.65     0.37 1.00     1165     3394\n#&gt; Intercept[Event2,4]    -0.50      0.80    -1.61     1.36 1.00     1151     3219\n#&gt; Intercept[Event2,5]     1.22      0.80     0.11     3.09 1.00     1136     3183\n#&gt; Intercept[Event3,1]    -6.01      3.01   -13.79    -2.01 1.00     1501      954\n#&gt; Intercept[Event3,2]    -3.56      1.63    -7.30    -1.02 1.00     1538     1243\n#&gt; Intercept[Event3,3]    -2.09      0.90    -3.48     0.02 1.00     1087     2748\n#&gt; Intercept[Event3,4]    -0.48      0.85    -1.60     1.57 1.00     1017     3002\n#&gt; Intercept[Event3,5]     1.16      0.85     0.05     3.22 1.00     1005     2911\n#&gt; Intercept[Event4,1]    -5.68      3.22   -14.18    -1.69 1.00     2057     1522\n#&gt; Intercept[Event4,2]    -3.21      1.52    -6.96    -0.67 1.00     2630     2764\n#&gt; Intercept[Event4,3]    -1.71      0.86    -3.13     0.19 1.00     1436     3028\n#&gt; Intercept[Event4,4]    -0.35      0.82    -1.53     1.55 1.00     1240     2942\n#&gt; Intercept[Event4,5]     1.49      0.82     0.32     3.40 1.00     1282     3273\n#&gt; Intercept[Event5,1]    -1.65      0.75    -2.92     0.04 1.00     1611     1805\n#&gt; Intercept[Event5,2]    -1.14      0.73    -2.38     0.49 1.00     1613     2456\n#&gt; Intercept[Event5,3]    -0.76      0.73    -1.99     0.89 1.00     1629     2350\n#&gt; Intercept[Event5,4]    -0.18      0.72    -1.39     1.45 1.00     1637     2360\n#&gt; Intercept[Event5,5]     1.46      0.73     0.28     3.09 1.00     1568     2333\n#&gt; Intercept[Event6,1]    -2.07      0.81    -3.57    -0.34 1.00     1275     2478\n#&gt; Intercept[Event6,2]    -1.78      0.78    -3.13    -0.06 1.00     1171     2301\n#&gt; Intercept[Event6,3]    -1.36      0.75    -2.57     0.33 1.00     1048     2427\n#&gt; Intercept[Event6,4]    -0.55      0.73    -1.66     1.12 1.00     1076     2288\n#&gt; Intercept[Event6,5]     0.79      0.73    -0.28     2.46 1.00     1111     2113\n#&gt; h241                    0.09      0.75    -1.69     1.64 1.00      950     1060\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; disc     1.00      0.00     1.00     1.00   NA       NA       NA\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "modules/workflow/index.html",
    "href": "modules/workflow/index.html",
    "title": "Workflow",
    "section": "",
    "text": "You are viewing the session notebook. Click here for slides."
  },
  {
    "objectID": "modules/workflow/index.html#problem",
    "href": "modules/workflow/index.html#problem",
    "title": "Workflow",
    "section": "Problem",
    "text": "Problem\nGenerally, we want to\n\nDo Bayesian data analyses\nWrite reproducible code\nSeek help effectively\nCollaborate with others\nMake code/work available?\n\nIn this intro, we look at tools that facilitate achieving these goals. The more complex your analyses get, the more helpful these tools (might?) be."
  },
  {
    "objectID": "modules/workflow/index.html#set-up",
    "href": "modules/workflow/index.html#set-up",
    "title": "Workflow",
    "section": "Set-up",
    "text": "Set-up\nLet’s first make sure we’ve set up the tools\n\n\nInstall Git\nRun git --version in a terminal\n\nTo ensure Git works\n\nCreate a GitHub account\nRun git clone https://github.com/mvuorre/workshop\n\nHelp connecting to GitHub here"
  },
  {
    "objectID": "modules/workflow/index.html#git",
    "href": "modules/workflow/index.html#git",
    "title": "Workflow",
    "section": "Git",
    "text": "Git\n\nGit is a version control tool—a program on your computer\nOrganize projects into repositories\n\nLocal repository: ~/Users/matti/Documents/workshop/ (actually ~/Users/matti/Documents/workshop/.git)\nRemote repository: https://github.com/mvuorre/workshop.git\n\nFunctions to\n\nCommit states to history\nPush and pull history from/to remote repository\nand more…\n\nPowers most software collaborations"
  },
  {
    "objectID": "modules/workflow/index.html#git-1",
    "href": "modules/workflow/index.html#git-1",
    "title": "Workflow",
    "section": "Git",
    "text": "Git\n\nGit can get extremely complicated\nI wrote a whole paper about it (Vuorre and Curley 2018), but still Kagi everything\nWe want to know just enough and not more\n\nhttps://happygitwithr.com/\nhttps://docs.github.com/en/get-started/using-github/github-flow\nhttps://www.atlassian.com/git/tutorials/comparing-workflows"
  },
  {
    "objectID": "modules/workflow/index.html#github",
    "href": "modules/workflow/index.html#github",
    "title": "Workflow",
    "section": "GitHub",
    "text": "GitHub\n\nGitHub is a Microsoft-owned developer platform owned by Microsoft\nGH hosts remote Git repositories with interesting additions (live demo)\nGet the workshop’s source code from GitHub:\n\n# In a directory where you're comfortable putting stuff\ngit clone https://github.com/mvuorre/workshop.git\ncd workshop.git\nThere are many alternative services such as GitLab and Codeberg."
  },
  {
    "objectID": "modules/workflow/index.html#collaborating-with-git-and-github",
    "href": "modules/workflow/index.html#collaborating-with-git-and-github",
    "title": "Workflow",
    "section": "Collaborating with Git and GitHub",
    "text": "Collaborating with Git and GitHub\nGeneral workflow for contributing to others’ projects\n\nFind a problem and let the author know about it\n\n–&gt; Submit an issue\n\nFix the problem and submit your fix\n\n–&gt; Submit a “pull request”\n\nIn many cases want to show examples of what’s going wrong and how\n\nReproducible example\nIdea applies equally to e.g. seeking help for your own problems on forums etc."
  },
  {
    "objectID": "modules/workflow/index.html#reproducible-examples",
    "href": "modules/workflow/index.html#reproducible-examples",
    "title": "Workflow",
    "section": "Reproducible examples",
    "text": "Reproducible examples\n\nLearn: https://speakerdeck.com/jennybc/reprex-reproducible-examples-with-r\nExample: https://github.com/mvuorre/brms-workshop/issues/1"
  },
  {
    "objectID": "modules/workflow/index.html#practice-1",
    "href": "modules/workflow/index.html#practice-1",
    "title": "Workflow",
    "section": "Practice 1",
    "text": "Practice 1\n\nCreate a reproducible example\nSubmit your reprex as a new “example” issue at https://github.com/mvuorre/workshop/issues\nWe’ll solve your problems together"
  },
  {
    "objectID": "modules/workflow/index.html#practice-2",
    "href": "modules/workflow/index.html#practice-2",
    "title": "Workflow",
    "section": "Practice 2",
    "text": "Practice 2\nLive example: Contributing to common repo (https://www.atlassian.com/git/tutorials/comparing-workflows)\n\nGet added as collaborator to https://github.com/brms-workshop/stuff\ngit clone https://github.com/brms-workshop/stuff.git\nFind code that needs fixing, and let others know with an issue\nFix code in a new branch\n\ne.g. Create a new file—this is an example.\n\nSubmit branch to GitHub and open a pull request\nDiscuss changes with others in pull request"
  },
  {
    "objectID": "modules/workflow/index.html#practice-3",
    "href": "modules/workflow/index.html#practice-3",
    "title": "Workflow",
    "section": "Practice 3",
    "text": "Practice 3\nLive example: Contributing to someone else’s repo\n\nFork the workshop repo to your GitHub account\nClone your remote repo to your computer\n\ngit clone https://github.com/{your-name}/workshop.git\n\nMake changes\n\nFor example, fix the reprex.R file\n\nPush local changes to your remote\nOpen a pull request\nDiscuss changes with others in pull request"
  },
  {
    "objectID": "modules/workflow/index.html#wrap-up",
    "href": "modules/workflow/index.html#wrap-up",
    "title": "Workflow",
    "section": "Wrap-up",
    "text": "Wrap-up\n\nBayesian statistics?!?\nReproducible examples are essential for seeking help\n\nThere will come a time when you need help!\n\nProper tools help us collaborate better\n\nhttps://www.youtube.com/watch?v=8qzVV7eEiaI\n\nVisibility\n\nCan choose public/private repos\nBe careful if this is something you’re concerned about"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "brms workshop",
    "section": "",
    "text": "We plan to tackle some or all of the topics below:\n\nCollaboration and workflow\nMultilevel models: Priors, outcome distributions, and model comparison\nOrdinal models\nSignal Detection Theoretic models\nCensored models\n\nOur plan is to walk through (some of) them, and edit the code to address your questions."
  },
  {
    "objectID": "index.html#plan",
    "href": "index.html#plan",
    "title": "brms workshop",
    "section": "",
    "text": "We plan to tackle some or all of the topics below:\n\nCollaboration and workflow\nMultilevel models: Priors, outcome distributions, and model comparison\nOrdinal models\nSignal Detection Theoretic models\nCensored models\n\nOur plan is to walk through (some of) them, and edit the code to address your questions."
  },
  {
    "objectID": "index.html#materials",
    "href": "index.html#materials",
    "title": "brms workshop",
    "section": "Materials",
    "text": "Materials\nThe materials of this workshop are organized in Quarto files. The source code is on GitHub."
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "brms workshop",
    "section": "Prerequisites",
    "text": "Prerequisites\nWe assume some familiarity with basic statistical modeling and the R language. If you’d like a refresher, see Introduction to Modern Statistics & R for Data Science. To follow along, you need to have\n\nR (https://cran.r-project.org/)\nAn R IDE like RStudio (recommended for beginners) or Positron (advanced)\nQuarto (for rendering the materials into a website)\nGit\nA GitHub account (if you want to participate in live troubleshooting / contributing)\n\n\nBuild / reproduce\nNote that building the project will run all the analysis documents, which involve bayesian models: This will take a long time. Because of this, you should first create an .Renviron file to describe your system settings (see .Renviron.example). For example,\necho \"\nMAX_CORES = 8\nBRMS_BACKEND = \"cmdstanr\"\nBRMS_THREADS = 2\nBRMS_ITER = 1000\n\" &gt;&gt; .Renviron\nThen, to recreate the materials locally, run the following in your terminal, not R. This will download the workshop materials (all source code), and then run the required code.\ngit clone https://github.com/mvuorre/workshop.git\ncd brms-workshop.git\nmake # (requires GNU Make)\nIf you don’t have make installed (i.e. you are on Windows), you need to first restore the R environment, prepare the data, and then render the project:\nR -e 'renv::restore(prompt = FALSE)'\nRscript prepare-data.R\nquarto render"
  },
  {
    "objectID": "index.html#contribute",
    "href": "index.html#contribute",
    "title": "brms workshop",
    "section": "Contribute",
    "text": "Contribute\nIssues & pull requests at https://github.com/mvuorre/workshop are welcome."
  },
  {
    "objectID": "modules/models/index.html",
    "href": "modules/models/index.html",
    "title": "Models",
    "section": "",
    "text": "Code\n# Packages\nlibrary(cmdstanr)\nlibrary(rstan)\nlibrary(scales)\nlibrary(knitr)\nlibrary(here)\nlibrary(janitor)\nlibrary(latex2exp)\nlibrary(distributional)\nlibrary(posterior)\nlibrary(patchwork)\nlibrary(tidybayes)\nlibrary(ggdist)\nlibrary(tidyverse)\n\n# Some settings common to all modules\nsource(here(\"modules/_common.R\"))"
  },
  {
    "objectID": "modules/models/index.html#what-is-it",
    "href": "modules/models/index.html#what-is-it",
    "title": "Models",
    "section": "What is it?",
    "text": "What is it?\n\n\n“Bayesian inference is reallocation of credibility across possibilities.” (Kruschke 2014)\n“Bayesian data analysis takes a question in the form of a model and uses logic to produce an answer in the form of probability distributions.” (McElreath 2020)\n“Bayesian inference is the process of fitting a probability model to a set of data and summarizing the result by a probability distribution on the parameters of the model and on unobserved quantities such as predictions for new observations.” (Gelman et al. 2013)"
  },
  {
    "objectID": "modules/models/index.html#what-is-it-1",
    "href": "modules/models/index.html#what-is-it-1",
    "title": "Models",
    "section": "What is it?",
    "text": "What is it?\n\nBayesian inference consists of updating prior information, using evidence in data, to posterior information\nUse probability distributions to express information (uncertainty)\n\n\n\nCode\ntibble(\n  shape1 = c(3, 10, 13),\n  shape2 = c(6, 4, 10),\n  beta = dist_beta(shape1, shape2),\n  name = factor(\n    c(\"Prior\", \"Likelihood\", \"Posterior\"),\n    levels = c(\"Prior\", \"Likelihood\", \"Posterior\"),\n    labels =\n      TeX(c(\"$p(\\\\theta)$\", \"$p(Y | \\\\theta)$\", \"$p(\\\\theta | Y)$\"))\n  )\n) |&gt;\n  ggplot() +\n  scale_color_brewer(\n    palette = \"Set1\",\n    labels = ~unname(\n      TeX(c(\"$p(\\\\theta)$\", \"$p(Y | \\\\theta)$\", \"$p(\\\\theta | Y)$\"))\n    ),\n    aesthetics = c(\"color\", \"fill\")\n  ) +\n  scale_y_continuous(\n    \"Probability density\",\n    expand = expansion(c(0, .1))\n  ) +\n  scale_x_continuous(\n    \"Parameter value\",\n    expand = expansion(c(0.01, 0.01))\n  ) +\n  stat_slab(\n    aes(xdist = beta, color = name),\n    fill = NA,\n    slab_linewidth = 1.5\n  ) +\n  theme(\n    legend.title = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    legend.position = \"right\"\n  )\n\n\n\n\n\n\n\n\nFigure 1: Bayesian inference combines prior information with data to produce a posterior distribution."
  },
  {
    "objectID": "modules/models/index.html#how-is-it-different-from-what-i-already-know",
    "href": "modules/models/index.html#how-is-it-different-from-what-i-already-know",
    "title": "Models",
    "section": "How is it different from what I already know?",
    "text": "How is it different from what I already know?\n\nBayesian data analysis may not be that different from what you already know (i.e. orthodox / classical / frequentist statistics)\nIn the absence of strong prior information, and presence of large data, the same model evaluated in a Bayesian or orthodox framework will yield the same numerical answers\nThe interpretations of, and philosophies behind the numbers are vastly different\nIn many ways, orthodox statistical methods can be thought of approximations to Bayesian methods\nHypothesis tests are very different between the two frameworks\nIn practice, Bayesian statistics are an extremely flexible modelling framework"
  },
  {
    "objectID": "modules/models/index.html#how-is-it-different-from-what-i-already-know-1",
    "href": "modules/models/index.html#how-is-it-different-from-what-i-already-know-1",
    "title": "Models",
    "section": "How is it different from what I already know?",
    "text": "How is it different from what I already know?\n\n\n\n\n\n\nFigure 2: McElreath (2020): “Example decision tree, or flowchart, for selecting an appropriate statistical procedure. Beginning at the top, the user answers a series of questions about measurement and intent, arriving eventually at the name of a procedure. Many such decision trees are possible.”"
  },
  {
    "objectID": "modules/models/index.html#what-can-it-do-for-me",
    "href": "modules/models/index.html#what-can-it-do-for-me",
    "title": "Models",
    "section": "What can it do for me?",
    "text": "What can it do for me?\nYou can estimate models in the Bayesian context that might not be otherwise possible. My first Bayesian analysis was conducted out of necessity. The model I wanted to use did not converge to a solution when I attempted to use orthodox methods (maximum likelihood estimation). Around the same time, I heard about Stan. I wrote some Stan code and the model converged without problems, and I was able to use the model that I wanted to.\nWith Bayes, you can actually be confident in your Confidence Intervals. I have a difficult time understanding p-values and Confidence Intervals. It can be difficult to understand what the uncertainty estimates mean when hypothetical replications are difficult to imagine in a given context. With a posterior distribution at hand, the corresponding probability values have a direct interpretation as credibility, uncertainty, or plausibility."
  },
  {
    "objectID": "modules/models/index.html#what-can-it-do-for-me-1",
    "href": "modules/models/index.html#what-can-it-do-for-me-1",
    "title": "Models",
    "section": "What can it do for me?",
    "text": "What can it do for me?\nBayesian methods allow easily carrying (un)certainty forward to other quantities of interest. It can often be difficult to obtain uncertainty estimates for various quantities when using orthodox methods. For example, effect size metrics are often reported without error bars (they can be obtained, but methods for doing so can be finicky and are not often used.)\nTo be sure, the Bayesian framework does not come for free. The methods might be difficult to communicate to others, at least until orthodox statistics are replaced in undergraduate applied statistics education. The necessity of complex computational algorithms makes it time-consuming—you will enjoy doing BDA more if you have a fast computer."
  },
  {
    "objectID": "modules/models/index.html#what-can-it-do-for-me-2",
    "href": "modules/models/index.html#what-can-it-do-for-me-2",
    "title": "Models",
    "section": "What can it do for me?",
    "text": "What can it do for me?\n\n\n\n\n\n\nFigure 3: Street cred is real (https://twitter.com/d_spiegel/status/550677361205977088)"
  },
  {
    "objectID": "modules/models/index.html#how-can-i-do-it",
    "href": "modules/models/index.html#how-can-i-do-it",
    "title": "Models",
    "section": "How can I do it?",
    "text": "How can I do it?\n\nIn theory\n\nWhat are the plausible values of parameters \\(\\theta\\) after observing data?\nThe posterior distribution \\(p(\\theta \\vert Y)\\) is the answer\nBayes’ theorem describes how to compute this distribution\n\n\\[\np(\\theta \\vert Y) = \\frac{p(Y \\vert \\theta) p(\\theta)}{p(Y)}\n\\]\n\n\\(p(Y \\vert \\theta)\\): likelihood function\nProbability of data given specific values for the model’s parameters\n\\(p(\\theta)\\): prior probability distribution on the parameters\nHow is plausibility distributed across possibilities before seeing data\n\\(p(Y)\\): marginal likelihood of the data\n\n\\[\np(\\theta \\vert Y) \\propto p(Y \\vert \\theta) p(\\theta).\n\\]"
  },
  {
    "objectID": "modules/models/index.html#how-can-i-do-it-1",
    "href": "modules/models/index.html#how-can-i-do-it-1",
    "title": "Models",
    "section": "How can I do it?",
    "text": "How can I do it?\n\nIn theory\n\\[\np(\\theta \\vert Y) \\propto p(Y \\vert \\theta) p(\\theta)\n\\]\nNeed to specify how the likelihood of each data point contributes to the parameters’ overall probability:\n\\[\np(\\theta \\vert Y) \\propto p(\\theta) \\prod^N_{n=1} p(y_i \\vert \\theta)\n\\]\nIn terms of programming, we think of adding up the log probabilities of each observation:\n\\[\n\\text{log}\\ p(\\theta \\vert Y) \\propto \\text{log}\\ p(\\theta) + \\sum^N_{n=1} \\text{log}\\ p(y_i \\vert \\theta)\n\\]"
  },
  {
    "objectID": "modules/models/index.html#how-can-i-do-it-2",
    "href": "modules/models/index.html#how-can-i-do-it-2",
    "title": "Models",
    "section": "How can I do it?",
    "text": "How can I do it?\n\n\n\n\n\n\nFigure 4: Homo Bayesianis"
  },
  {
    "objectID": "modules/models/index.html#how-can-i-do-it-3",
    "href": "modules/models/index.html#how-can-i-do-it-3",
    "title": "Models",
    "section": "How can I do it?",
    "text": "How can I do it?\n\nIn practice\n\nTarget of inference is the posterior distribution\nMany interesting models’ posterior distributions do not have solutions\nMarkov Chain Monte Carlo (MCMC) techniques allow us to approximate distributions by drawing random samples from them\nBUGS, JAGS, PyMC, Stan"
  },
  {
    "objectID": "modules/models/index.html#how-can-i-do-it-4",
    "href": "modules/models/index.html#how-can-i-do-it-4",
    "title": "Models",
    "section": "How can I do it?",
    "text": "How can I do it?\n\nIn practice\n\n\nCode\nlibrary(brms)\n\n\n\n\n\n\n\n\nFigure 5: brms logo\n\n\n\n\nbrms converts R modelling syntax to Stan and extends it in interesting ways\nHigh-level interface to Stan allow us to avoid writing raw Stan code\nhttps://discourse.mc-stan.org/"
  },
  {
    "objectID": "modules/models/index.html#this-section",
    "href": "modules/models/index.html#this-section",
    "title": "Models",
    "section": "This section",
    "text": "This section\n\nDiscuss a concise modeling workflow\nImplement it in practice\nA model with gaussian outcome and one continuous predictor\nEstablish notation following McElreath (2020)"
  },
  {
    "objectID": "modules/models/index.html#why-models",
    "href": "modules/models/index.html#why-models",
    "title": "Models",
    "section": "Why models?",
    "text": "Why models?\n\nWhat is the role and goal of statistics in science?\n…\nWe want to build models with parameters whose estimated magnitudes inform theories\nWe want to test hypothesized differences between means\nBayes allows us to use probability to quantify uncertainty about these parameters, and compare and criticize the models themselves"
  },
  {
    "objectID": "modules/models/index.html#bayesian-workflow",
    "href": "modules/models/index.html#bayesian-workflow",
    "title": "Models",
    "section": "Bayesian workflow",
    "text": "Bayesian workflow\nTo get started with BDA, it is useful to first informally define what a “Bayesian workflow” might look like. Following Kruschke (2014, 25), we identify five key data analysis steps\n\nIdentify data relevant to the research question.\nDefine a descriptive model, whose parameters capture the research question.\nSpecify prior probability distributions on parameters in the model.\nUpdate the prior to a posterior distribution using Bayesian inference.\nCheck your model against data, and identify possible problems."
  },
  {
    "objectID": "modules/models/index.html#bayesian-workflow-1",
    "href": "modules/models/index.html#bayesian-workflow-1",
    "title": "Models",
    "section": "Bayesian workflow",
    "text": "Bayesian workflow\nA more complete treatment is found in Gelman et al. (2020) (Figure 6).\n\n\n\n\n\n\nFigure 6: Figure 1 from (Gelman et al. 2020): “Overview of the steps we currently consider in Bayesian workflow. Numbers in brackets refer to sections of this paper where the steps are discussed. The chart aims to show possible steps and paths an individual analysis may go through, with the understanding that any particular analysis will most likely not involve all of these steps. One of our goals in studying workflow is to understand how these ideas fit together so they can be applied more systematically.”"
  },
  {
    "objectID": "modules/models/index.html#identify-relevant-data",
    "href": "modules/models/index.html#identify-relevant-data",
    "title": "Models",
    "section": "Identify relevant data",
    "text": "Identify relevant data\n\n(Research question, experimentation, measurement…)\nDefine outcomes (DVs) and predictors (IVs)\nWhat are the scales? Were variables measured or manipulated? …\n\nWe collected data on the effects of sleep deprivation on cognitive performance, as measured by reaction time on a cognitive task. The data are observations of 18 individuals’ reaction times across 8 days of sleep deprivation (Table 1)\n\n\nCode\ndat &lt;- tibble(lme4::sleepstudy) |&gt;\n  clean_names() |&gt;\n  # First two days (0 and 1) were an adaptation period\n  filter(days &gt;= 2) |&gt;\n  mutate(days = days - 2)\n\n\n\n\n\n\n\n\n\n\nreaction\ndays\nsubject\n\n\n\n\n251\n0\n308\n\n\n321\n1\n308\n\n\n357\n2\n308\n\n\n415\n3\n308\n\n\n382\n4\n308\n\n\n290\n5\n308\n\n\n\n\n\n\nTable 1: First six rows of sleep study data."
  },
  {
    "objectID": "modules/models/index.html#identify-relevant-data-1",
    "href": "modules/models/index.html#identify-relevant-data-1",
    "title": "Models",
    "section": "Identify relevant data",
    "text": "Identify relevant data\n\nThe way in which we ran this experiment (we didn’t!) would dictate, to a large extent, the variables and their roles in our analysis\nThere might be several other important variables to consider, such as how much a person typically sleeps, or whether they are trained on the cognitive task\nSome or all of those variables might not exist in our data, but might guide our thinking nevertheless"
  },
  {
    "objectID": "modules/models/index.html#define-a-model",
    "href": "modules/models/index.html#define-a-model",
    "title": "Models",
    "section": "Define a model",
    "text": "Define a model\n\nA creative process\nJust because they are all wrong doesn’t mean you shouldn’t try to be less wrong\nHow are the outcomes distributed conditional on the predictors?\nAre there natural bounds in the data? Are the data collected on a continuous or categorical scale?\nWhat are the relations between variables? Are they linear or more complicated?\nWe will build a series of increasingly complex & informative models for these data"
  },
  {
    "objectID": "modules/models/index.html#define-a-model-1",
    "href": "modules/models/index.html#define-a-model-1",
    "title": "Models",
    "section": "Define a model",
    "text": "Define a model\n\n“Null” model (no predictors)\nWe assume that the reaction times \\(y_i\\) in \\(1, \\dots, N\\) are normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma\\)\n\n\\[\ny_i = \\mu + \\epsilon_i, \\epsilon_i \\sim N(0, \\sigma^2)\n\\]\nWe prefer the following “distributional” notation for its conciseness and emphasis on data rather than errors\n\\[\ny_i \\sim N(\\mu, \\sigma^2)\n\\]\n\n\nCode\nbf0 &lt;- bf(reaction ~ 1)"
  },
  {
    "objectID": "modules/models/index.html#prior-distribution",
    "href": "modules/models/index.html#prior-distribution",
    "title": "Models",
    "section": "Prior distribution",
    "text": "Prior distribution\n\nA prior distribution is the distribution of plausible values a parameter can take, before the data are observed.\nIt is sometimes pointed at when critics claim that Bayesian statistics are subjective and therefore useless.\nThe prior distribution is only one part of a model chosen by the analyst.\nSpecifying priors requires care, and often a vague or even a prior that is constant over the parameter values can be a useful starting point.\nWe would be guided by our expert knowledge of this topic and design of the experiment"
  },
  {
    "objectID": "modules/models/index.html#prior-distribution-1",
    "href": "modules/models/index.html#prior-distribution-1",
    "title": "Models",
    "section": "Prior distribution",
    "text": "Prior distribution\nFor our first example, we let {brms} set default priors. These are weakly informative and only serve to facilitate model convergence.\n\n\nCode\nget_prior(bf0, dat)[,-c(3:7, 9)]\n#&gt;                      prior     class lb  source\n#&gt;  student_t(3, 303.2, 65.5) Intercept    default\n#&gt;      student_t(3, 0, 65.5)     sigma  0 default\n\n\n\n\nCode\nget_prior(bf0, dat) |&gt;\n  parse_dist() |&gt;\n  ggplot(aes(y = class)) +\n  scale_x_continuous(\n    \"Parameter value\",\n    breaks = extended_breaks(7)\n  ) +\n  stat_halfeye(\n    aes(xdist = .dist_obj)\n  ) +\n  theme(\n    axis.title.y = element_blank()\n  )"
  },
  {
    "objectID": "modules/models/index.html#prior-distribution-2",
    "href": "modules/models/index.html#prior-distribution-2",
    "title": "Models",
    "section": "Prior distribution",
    "text": "Prior distribution\n\nIf you wish to “let the data speak for itself”, the prior can be set to a constant over the possible values of the parameter.\nWhether such a noninformative or flat prior leads to a “Bayesian” analysis is, however, debatable.\nCurrently, so called weakly informative priors are popular, because they help prevent certain computational issues in sampling from the model’s posterior distribution, while remaining mostly uninformative about the parameter values.\nInformative priors have a substantial impact on the posterior distribution\nUseful when strong prior information is available\nRequired for hypothesis testing (e.g. Bayes factors)\nIt is OK to start with a noninformative prior, but you will likely be able to tell how implausible such a starting point can be with further thought & simulation.\nKruschke suggests that a prior should be chosen such that you could defend it in front of a sceptical audience\nChoosing priors vs. likelihood functions"
  },
  {
    "objectID": "modules/models/index.html#sampling-from-the-posterior-with-brm",
    "href": "modules/models/index.html#sampling-from-the-posterior-with-brm",
    "title": "Models",
    "section": "Sampling from the posterior with brm()",
    "text": "Sampling from the posterior with brm()\n\n\nCode\nfit0 &lt;- brm(\n  formula = reaction ~ 1,\n  family = gaussian(), \n  data = dat,\n  file = here(\"models/introduction-0\")\n)"
  },
  {
    "objectID": "modules/models/index.html#sampling-from-the-posterior-with-brm-1",
    "href": "modules/models/index.html#sampling-from-the-posterior-with-brm-1",
    "title": "Models",
    "section": "Sampling from the posterior with brm()",
    "text": "Sampling from the posterior with brm()\nUse environment variables to separate settings from source code.\n\n\n.Renviron\n\nMAX_CORES = 8\nBRMS_BACKEND = \"cmdstanr\"\nBRMS_THREADS = 2\n\nRefer to environment variables when setting default HMC sampler options\n\n\n_common.R\n\noptions(\n  brms.backend = Sys.getenv(\"BRMS_BACKEND\", \"rstan\"),\n  brms.threads = as.numeric(Sys.getenv(\"BRMS_THREADS\"), 1),\n  mc.cores = as.numeric(Sys.getenv(\"MAX_CORES\"), 4)\n)\n\nbrm() uses options() for several arguments (see ?brm).\n\ncmdstanr\n\nhttps://mc-stan.org/cmdstanr/index.html\nhttp://mc-stan.org/cmdstanr/articles/cmdstanr.html#comparison-with-rstan\nUp to date Stan; faster (YMMV); threading\nrenv::install(\"stan-dev/cmdstanr\")\nremotes::install_github(\"stan-dev/cmdstanr\")"
  },
  {
    "objectID": "modules/models/index.html#model-checking",
    "href": "modules/models/index.html#model-checking",
    "title": "Models",
    "section": "Model checking",
    "text": "Model checking\nEstimation relies on computational algorithms that can fail to deliver. This is unlikely with gaussian and other simple models, but checking should be done nevertheless.\n\n\nCode\nplot(fit0)"
  },
  {
    "objectID": "modules/models/index.html#model-checking-1",
    "href": "modules/models/index.html#model-checking-1",
    "title": "Models",
    "section": "Model checking",
    "text": "Model checking\nMore checking, and interpreting quantities.\n\n\nCode\nsummary(fit0)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: reaction ~ 1 \n#&gt;    Data: dat (Number of observations: 144) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   307.86      4.85   298.39   317.67 1.00     3427     2112\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma    57.33      3.36    51.14    64.35 1.00     3259     2616\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "modules/models/index.html#posterior-predictive-check",
    "href": "modules/models/index.html#posterior-predictive-check",
    "title": "Models",
    "section": "Posterior predictive check",
    "text": "Posterior predictive check\nOnce a posterior distribution is obtained, it is prudent to check whether it makes reasonable predictions; if it “fits the data” well. This is sometimes called posterior predictive checking, because we use the posterior to generate predictions that are then checked against data. These checks can focus on the overall “fit” of the model…\n\n\nCode\npp_check(\n  fit0, \n  type = \"hist\", \n  ndraws = 5\n) +\n  scale_x_continuous(\"Reaction time (ms)\")"
  },
  {
    "objectID": "modules/models/index.html#posterior-predictive-check-1",
    "href": "modules/models/index.html#posterior-predictive-check-1",
    "title": "Models",
    "section": "Posterior predictive check",
    "text": "Posterior predictive check\n…or focus on particular aspects of the data, such as the mean and sd\n\n\nCode\npp_check(fit0, type = \"stat_2d\", stat = c(\"mean\", \"sd\"))"
  },
  {
    "objectID": "modules/models/index.html#posterior-predictive-check-2",
    "href": "modules/models/index.html#posterior-predictive-check-2",
    "title": "Models",
    "section": "Posterior predictive check",
    "text": "Posterior predictive check\n…or some other summaries\n\n\nCode\n\npp_check(fit0, type = \"stat_2d\", stat = c(\"min\", \"max\"))"
  },
  {
    "objectID": "modules/models/index.html#model-2",
    "href": "modules/models/index.html#model-2",
    "title": "Models",
    "section": "Model 2",
    "text": "Model 2\n\nThe previous was a “null” model; did not include predictors\nWhat is the effect of one day of sleep deprivation on reaction time\n\n\\[\ny_i \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2),\n\\]\n\n\\(\\beta_0\\) is the intercept\n\\(\\beta_1\\) is the coefficient of days, \\(x_i\\).\n\\(\\sigma\\) is the residual standard deviation\n\n\n\nCode\nbf1 &lt;- bf(reaction ~ days)"
  },
  {
    "objectID": "modules/models/index.html#priors",
    "href": "modules/models/index.html#priors",
    "title": "Models",
    "section": "Priors",
    "text": "Priors\n\n\nCode\nget_prior(bf1, dat)[,-c(3:7, 9)]\n#&gt;                      prior     class lb  source\n#&gt;                     (flat)         b    default\n#&gt;                     (flat)         b    default\n#&gt;  student_t(3, 303.2, 65.5) Intercept    default\n#&gt;      student_t(3, 0, 65.5)     sigma  0 default\np &lt;- prior(student_t(7, 300, 200), class = \"Intercept\") +\n  prior(student_t(7, 0, 100), class = \"b\", coef = \"days\") +\n  prior(student_t(7, 0, 50), class = \"sigma\", lb = 0)\np[,-c(3:7, 9)]\n#&gt;                   prior     class   lb source\n#&gt;  student_t(7, 300, 200) Intercept &lt;NA&gt;   user\n#&gt;    student_t(7, 0, 100)         b &lt;NA&gt;   user\n#&gt;     student_t(7, 0, 50)     sigma    0   user"
  },
  {
    "objectID": "modules/models/index.html#sample-from-the-posterior",
    "href": "modules/models/index.html#sample-from-the-posterior",
    "title": "Models",
    "section": "Sample from the posterior",
    "text": "Sample from the posterior\n\n\nCode\nfit1 &lt;- brm(\n  bf1,\n  family = gaussian(),\n  data = dat,\n  prior = p,\n  sample_prior = \"yes\",\n  # file = here(\"models/introduction-1\")\n)\n#&gt; Running MCMC with 4 chains, at most 8 in parallel, with 2 thread(s) per chain...\n#&gt; \n#&gt; Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \n#&gt; Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \n#&gt; Chain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \n#&gt; Chain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \n#&gt; Chain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \n#&gt; Chain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \n#&gt; Chain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \n#&gt; Chain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \n#&gt; Chain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \n#&gt; Chain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \n#&gt; Chain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \n#&gt; Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n#&gt; Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n#&gt; Chain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \n#&gt; Chain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \n#&gt; Chain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \n#&gt; Chain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \n#&gt; Chain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n#&gt; Chain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \n#&gt; Chain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \n#&gt; Chain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \n#&gt; Chain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \n#&gt; Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \n#&gt; Chain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \n#&gt; Chain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \n#&gt; Chain 2 finished in 0.1 seconds.\n#&gt; Chain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \n#&gt; Chain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \n#&gt; Chain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \n#&gt; Chain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \n#&gt; Chain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \n#&gt; Chain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \n#&gt; Chain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \n#&gt; Chain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \n#&gt; Chain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \n#&gt; Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n#&gt; Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n#&gt; Chain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \n#&gt; Chain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \n#&gt; Chain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \n#&gt; Chain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \n#&gt; Chain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n#&gt; Chain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \n#&gt; Chain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \n#&gt; Chain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \n#&gt; Chain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \n#&gt; Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \n#&gt; Chain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \n#&gt; Chain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \n#&gt; Chain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \n#&gt; Chain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \n#&gt; Chain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \n#&gt; Chain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \n#&gt; Chain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \n#&gt; Chain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \n#&gt; Chain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \n#&gt; Chain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n#&gt; Chain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n#&gt; Chain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \n#&gt; Chain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \n#&gt; Chain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \n#&gt; Chain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \n#&gt; Chain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n#&gt; Chain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \n#&gt; Chain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \n#&gt; Chain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \n#&gt; Chain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \n#&gt; Chain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \n#&gt; Chain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \n#&gt; Chain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \n#&gt; Chain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \n#&gt; Chain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \n#&gt; Chain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \n#&gt; Chain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \n#&gt; Chain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \n#&gt; Chain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \n#&gt; Chain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \n#&gt; Chain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n#&gt; Chain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n#&gt; Chain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \n#&gt; Chain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \n#&gt; Chain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \n#&gt; Chain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \n#&gt; Chain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n#&gt; Chain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \n#&gt; Chain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \n#&gt; Chain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \n#&gt; Chain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \n#&gt; Chain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \n#&gt; Chain 1 finished in 0.2 seconds.\n#&gt; Chain 3 finished in 0.2 seconds.\n#&gt; Chain 4 finished in 0.2 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.2 seconds.\n#&gt; Total execution time: 0.4 seconds."
  },
  {
    "objectID": "modules/models/index.html#model-checking-2",
    "href": "modules/models/index.html#model-checking-2",
    "title": "Models",
    "section": "Model checking",
    "text": "Model checking\n\n\nCode\nsummary(fit1)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: reaction ~ days \n#&gt;    Data: dat (Number of observations: 144) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   267.98      7.80   252.79   283.03 1.00     4043     2825\n#&gt; days         11.44      1.83     7.82    15.07 1.00     3987     2870\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma    51.08      3.02    45.59    57.30 1.00     4335     3008\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "modules/models/index.html#model-checking-3",
    "href": "modules/models/index.html#model-checking-3",
    "title": "Models",
    "section": "Model checking",
    "text": "Model checking\n\n\nCode\nplot(fit1)"
  },
  {
    "objectID": "modules/models/index.html#posterior-predictive-check-3",
    "href": "modules/models/index.html#posterior-predictive-check-3",
    "title": "Models",
    "section": "Posterior predictive check",
    "text": "Posterior predictive check\n\n\nCode\npp_check(fit1, type = \"stat_2d\", stat = c(\"min\", \"max\"))\n\n\n\n\n\n\n\n\n\n\nWhat is happening?\n\n\n\nCode\npp_check(fit1)"
  },
  {
    "objectID": "modules/models/index.html#posterior-predictive-check-4",
    "href": "modules/models/index.html#posterior-predictive-check-4",
    "title": "Models",
    "section": "Posterior predictive check",
    "text": "Posterior predictive check\n\n\nCode\nset.seed(1)\np1 &lt;- dat |&gt;\n  ggplot(aes(days, reaction)) +\n  scale_x_continuous(breaks = pretty_breaks(9)) +\n  scale_y_continuous(breaks = pretty_breaks(5)) +\n  labs(\n    x = \"days of sleep deprivation\", \n    y = \"RT\"\n  )\n\ntmp &lt;- spread_draws(\n  fit1,\n  prior_Intercept, prior_b_days,\n  ndraws = 30\n) |&gt;\n  crossing(dat) |&gt;\n  rowwise() |&gt;\n  mutate(\n    .value = prior_Intercept + prior_b_days * days\n  )\n\np2 &lt;- p1 %+%\n  tmp +\n  aes(y = .value, group = .draw) +\n  geom_line(alpha = .05) +\n  labs(\n    x = \"days of sleep deprivation\", \n    y = \"Prior predicted mean RT\"\n  )\n\np3 &lt;- p2 %+%\n  add_epred_draws(dat, fit1, ndraws = 30) +\n  aes(y = .epred) +\n  labs(\n    x = \"days of sleep deprivation\", \n    y = \"Posterior predicted mean RT\"\n  )\n\n(p2 | p1 + geom_point() | p3) & \n  coord_cartesian(ylim = c(-500, 1000))"
  },
  {
    "objectID": "modules/models/index.html#summarising-the-posterior-distribution",
    "href": "modules/models/index.html#summarising-the-posterior-distribution",
    "title": "Models",
    "section": "Summarising the posterior distribution",
    "text": "Summarising the posterior distribution\n\n\nCode\ngather_draws(fit1, b_Intercept, b_days, sigma) |&gt;\n  ggplot(aes(y = .variable, x = .value)) +\n  stat_histinterval(breaks = 50) +\n  scale_x_continuous(\"Parameter value\") +\n  theme(axis.title.y = element_blank())\n\n\n\n\n\n\n\n\n\nLet’s write a function to report useful numbers\n\n\nCode\nsm &lt;- \\(\n  x, \n  v = c(\"^b_\", \"^sd_\", \"^cor_\", \"^sigma\"), \n  r = TRUE\n) {\n  as_draws_df(x, variable = v, regex = r) |&gt; \n    summarise_draws(\n      mean, sd, \n      ~quantile2(.x, c(0.025, 0.975)),\n      pd = ~Pr(sign(.x) == sign(median(.x))),\n      rhat, ess_tail\n    )\n}\nsm(fit1)\n#&gt; # A tibble: 3 × 8\n#&gt;   variable     mean    sd   q2.5 q97.5    pd  rhat ess_tail\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 268.   7.80 253.   283.      1  1.00    2825.\n#&gt; 2 b_days       11.4  1.83   7.82  15.1     1  1.00    2870.\n#&gt; 3 sigma        51.1  3.02  45.6   57.3     1  1.00    3008.\n\n\n\n\nCode\nsm(fit1) |&gt; \n  mutate(\n    `95%CI` = str_glue(\n      \"[{number(q2.5, .01)}, {number(q97.5, .01)}]\"\n    ),\n    .after = 3\n  ) |&gt; \n  select(\n    -starts_with(\"q\")\n  ) |&gt; \n  kable()\n\n\n\n\n\nvariable\nmean\nsd\n95%CI\npd\nrhat\ness_tail\n\n\n\n\nb_Intercept\n268\n7.8\n[252.79, 283.03]\n1\n1\n2825\n\n\nb_days\n11\n1.8\n[7.82, 15.07]\n1\n1\n2870\n\n\nsigma\n51\n3.0\n[45.59, 57.30]\n1\n1\n3008"
  },
  {
    "objectID": "modules/models/index.html#meet-the-s-x-p-matrix",
    "href": "modules/models/index.html#meet-the-s-x-p-matrix",
    "title": "Models",
    "section": "Meet the S x P matrix",
    "text": "Meet the S x P matrix\n\n\nCode\npost &lt;- as_draws_df(fit1)\npost[,1:6]\n#&gt; # A tibble: 4,000 × 6\n#&gt;    b_Intercept b_days sigma Intercept prior_Intercept prior_b_days\n#&gt;          &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;           &lt;dbl&gt;        &lt;dbl&gt;\n#&gt;  1        270.  11.7   52.5      311.            346.        -37.7\n#&gt;  2        264.  12.6   53.1      308.            146.       -363. \n#&gt;  3        273.   9.37  49.6      306.            232.        110. \n#&gt;  4        255.  13.2   56.1      301.            106.        -14.2\n#&gt;  5        267.   9.43  55.1      300.            197.         94.2\n#&gt;  6        271.   7.22  53.2      296.            491.       -119. \n#&gt;  7        273.   7.30  53.2      299.            406.        159. \n#&gt;  8        275.   9.53  53.7      308.           -200.        182. \n#&gt;  9        272.  11.0   45.5      310.            402.        104. \n#&gt; 10        272.  11.4   56.9      312.            771.        -92.5\n#&gt; # ℹ 3,990 more rows\n\n\n\n\nCode\npost$qoi &lt;- post$b_days / post$sigma\nsm(post)\n#&gt; # A tibble: 10 × 8\n#&gt;    variable            mean       sd     q2.5    q97.5    pd  rhat ess_tail\n#&gt;    &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 b_Intercept      268.      7.80    253.     283.    1      1.00    2825.\n#&gt;  2 b_days            11.4     1.83      7.82    15.1   1      1.00    2870.\n#&gt;  3 sigma             51.1     3.02     45.6     57.3   1      1.00    3008.\n#&gt;  4 Intercept        308.      4.26    300.     316.    1      1.00    2815.\n#&gt;  5 prior_Intercept  301.    237.     -170.     791.    0.910  1.00    4142.\n#&gt;  6 prior_b_days      -1.34  118.     -249.     223.    0.502  1.00    3501.\n#&gt;  7 prior_sigma       45.2    38.7       1.79   140.    1      1.00    3501.\n#&gt;  8 lprior           -16.6     0.0619  -16.7    -16.4   1      1.00    3033.\n#&gt;  9 lp__            -783.      1.22   -786.    -782.    1      1.00    2400.\n#&gt; 10 qoi                0.225   0.0380    0.150    0.300 1      1.00    2809."
  },
  {
    "objectID": "modules/models/index.html#posterior-predictive-check-5",
    "href": "modules/models/index.html#posterior-predictive-check-5",
    "title": "Models",
    "section": "Posterior predictive check",
    "text": "Posterior predictive check\n\n\nCode\npp_check(fit1, ndraws = 30)"
  },
  {
    "objectID": "modules/models/index.html#posterior-predictive-check-6",
    "href": "modules/models/index.html#posterior-predictive-check-6",
    "title": "Models",
    "section": "Posterior predictive check",
    "text": "Posterior predictive check\n\n\nCode\npp_check(fit1, type = \"stat_2d\", stat = c(\"min\", \"max\"))"
  },
  {
    "objectID": "modules/models/index.html#conditional-effects",
    "href": "modules/models/index.html#conditional-effects",
    "title": "Models",
    "section": "Conditional effects",
    "text": "Conditional effects\n\n\nCode\nplot(\n  conditional_effects(fit1, \"days\"), \n  points = TRUE\n)\n\n\n\n\n\n\n\n\n\n\nPerhaps we should model variance on days?"
  },
  {
    "objectID": "modules/models/index.html#location-scale-model-1",
    "href": "modules/models/index.html#location-scale-model-1",
    "title": "Models",
    "section": "Location-scale model",
    "text": "Location-scale model\n\\[\n\\begin{aligned}\ny_i &\\sim N(\\mu, \\sigma^2), \\\\\n\\mu &= \\beta_0 + \\beta_1 x_i, \\\\\n\\sigma &= \\text{exp}(\\gamma_0 + \\gamma_1x_1).\n\\end{aligned}\n\\]\n\n\nCode\nbf2 &lt;- bf(reaction ~ days) + lf(sigma ~ days)\n\nget_prior(bf2, dat)[,c(1:3, 6, 10)]\n#&gt;                      prior     class coef  dpar  source\n#&gt;                     (flat)         b            default\n#&gt;                     (flat)         b days       default\n#&gt;  student_t(3, 303.2, 65.5) Intercept            default\n#&gt;                     (flat)         b      sigma default\n#&gt;                     (flat)         b days sigma default\n#&gt;       student_t(3, 0, 2.5) Intercept      sigma default"
  },
  {
    "objectID": "modules/models/index.html#location-scale-model-2",
    "href": "modules/models/index.html#location-scale-model-2",
    "title": "Models",
    "section": "Location-scale model",
    "text": "Location-scale model\n\n\nCode\nfit2 &lt;- brm(\n  bf2,\n  data = dat,\n  control = list(adapt_delta = .95),\n  file = here(\"models/introduction-2\")\n)\n\n\nBy the way this is equivalent to\n#| echo: true\n\nfit2 &lt;- brm(\n  bf(reaction ~ days, sigma ~ days),\n  data = dat\n)"
  },
  {
    "objectID": "modules/models/index.html#summarising-the-posterior-distribution-1",
    "href": "modules/models/index.html#summarising-the-posterior-distribution-1",
    "title": "Models",
    "section": "Summarising the posterior distribution",
    "text": "Summarising the posterior distribution\n\n\nCode\nsummary(fit2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = log \n#&gt; Formula: reaction ~ days \n#&gt;          sigma ~ days\n#&gt;    Data: sleepstudy (Number of observations: 144) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma_Intercept     3.54      0.12     3.32     3.77 1.00     2623     2686\n#&gt; Intercept         267.56      6.02   255.57   279.44 1.00     1836     2143\n#&gt; days               11.57      1.83     8.03    15.26 1.00     1907     2411\n#&gt; sigma_days          0.10      0.03     0.05     0.16 1.00     2638     2387\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "modules/models/index.html#summarising-the-posterior-distribution-2",
    "href": "modules/models/index.html#summarising-the-posterior-distribution-2",
    "title": "Models",
    "section": "Summarising the posterior distribution",
    "text": "Summarising the posterior distribution\n\n\nCode\nfit2 |&gt;\n  gather_draws(b_days, b_sigma_days) |&gt;\n  ggplot(aes(.value, .variable)) +\n  stat_histinterval()"
  },
  {
    "objectID": "modules/models/index.html#model-comparison",
    "href": "modules/models/index.html#model-comparison",
    "title": "Models",
    "section": "Model comparison",
    "text": "Model comparison\n\n\nCode\n# Add LOO criteria to all models\nfit0 &lt;- add_criterion(fit0, \"loo\")\nfit1 &lt;- add_criterion(fit1, \"loo\")\nfit2 &lt;- add_criterion(fit2, \"loo\")\n\n\n\n\nCode\nloo(fit0)\n#&gt; \n#&gt; Computed from 4000 by 144 log-likelihood matrix.\n#&gt; \n#&gt;          Estimate   SE\n#&gt; elpd_loo   -788.2  8.3\n#&gt; p_loo         1.9  0.4\n#&gt; looic      1576.5 16.6\n#&gt; ------\n#&gt; MCSE of elpd_loo is 0.0.\n#&gt; MCSE and ESS estimates assume MCMC draws (r_eff in [0.7, 0.9]).\n#&gt; \n#&gt; All Pareto k estimates are good (k &lt; 0.7).\n#&gt; See help('pareto-k-diagnostic') for details.\n\n\n\nhttps://users.aalto.fi/%7Eave/CV-FAQ.html#12_What_is_the_interpretation_of_ELPD__elpd_loo__elpd_diff\nhttps://mc-stan.org/loo/reference/loo-glossary.html\n\n\nelpd_loo is the Bayesian LOO estimate of the expected log pointwise predictive density (Eq 4 in VGG2017) and is a sum of N individual pointwise log predictive densities. Probability densities can be smaller or larger than 1, and thus log predictive densities can be negative or positive. For simplicity the ELPD acronym is used also for expected log pointwise predictive probabilities for discrete models. Probabilities are always equal or less than 1, and thus log predictive probabilities are 0 or negative.\n\n\n\nCode\nloo_compare(\n  fit0, fit1, fit2\n)\n#&gt;      elpd_diff se_diff\n#&gt; fit2   0.0       0.0  \n#&gt; fit1  -5.9       3.3  \n#&gt; fit0 -22.0       6.1\n\n\n\nelpd_diff is the difference in elpd_loo for two models. If more than two models are compared, the difference is computed relative to the model with highest elpd_loo.\n\n\nAs quick rule: If elpd difference (elpd_diff in loo package) is less than 4, the difference is small (Sivula, Magnusson and Vehtari, 2020, p. McLatchie+etal:2023). If elpd difference (elpd_diff in loo package) is larger than 4, then compare that difference to standard error of elpd_diff (provided e.g. by loo package) (Sivula, Magnusson and Vehtari, 2020).\n\n\nSometimes Theory &gt; model comparison"
  },
  {
    "objectID": "modules/models/index.html#why",
    "href": "modules/models/index.html#why",
    "title": "Models",
    "section": "Why",
    "text": "Why\n\n\nCode\ndat |&gt; \n  ggplot(aes(days, reaction)) +\n  geom_point() +\n  geom_smooth(method = \"loess\")"
  },
  {
    "objectID": "modules/models/index.html#reaction-time-data",
    "href": "modules/models/index.html#reaction-time-data",
    "title": "Models",
    "section": "Reaction time data",
    "text": "Reaction time data\n\nhttps://lindeloev.github.io/shiny-rt/\nFor convenience, we choose a shifted lognormal distribution\n\n\n\nCode\nfitrt1 &lt;- brm(\n  bf(reaction ~ days) + shifted_lognormal(),\n  data = dat,\n  control = list(adapt_delta = .95),\n  file = here(\"models/introduction-sln-1\")\n)\nfitrt1 &lt;- add_criterion(fitrt1, \"loo\")\nloo_compare(fit1, fitrt1)\n#&gt;        elpd_diff se_diff\n#&gt; fitrt1  0.0       0.0   \n#&gt; fit1   -1.0       2.6\n\n\n\n\nCode\nsummary(fitrt1)\n#&gt;  Family: shifted_lognormal \n#&gt;   Links: mu = identity; sigma = identity; ndt = identity \n#&gt; Formula: reaction ~ days \n#&gt;    Data: dat (Number of observations: 144) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     5.29      0.20     4.86     5.58 1.00      635     1043\n#&gt; days          0.05      0.01     0.03     0.07 1.00      951     1159\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     0.22      0.04     0.16     0.32 1.00      692     1169\n#&gt; ndt      64.79     37.38     3.50   134.98 1.01      642      948\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\nCode\nplot(conditional_effects(fitrt1), points = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nCode\npp_check(fitrt1)\n\n\n\n\n\n\n\n\n\nModel variance too\n\n\nCode\nfitrt2 &lt;- brm(\n  bf(reaction ~ days) + \n    lf(sigma ~ days) +\n    shifted_lognormal(),\n  data = dat,\n  control = list(adapt_delta = .95),\n  file = here(\"models/introduction-sln-2\")\n)\nfitrt2 &lt;- add_criterion(fitrt2, \"loo\")\nloo_compare(fitrt1, fitrt2)\n#&gt;        elpd_diff se_diff\n#&gt; fitrt2  0.0       0.0   \n#&gt; fitrt1 -2.2       2.2\n\n\n\n\nCode\nsummary(fitrt2)\n#&gt;  Family: shifted_lognormal \n#&gt;   Links: mu = identity; sigma = log; ndt = identity \n#&gt; Formula: reaction ~ days \n#&gt;          sigma ~ days\n#&gt;    Data: dat (Number of observations: 144) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept           5.39      0.16     5.00     5.59 1.00      741     1076\n#&gt; sigma_Intercept    -1.86      0.20    -2.19    -1.42 1.00      884     1110\n#&gt; days                0.04      0.01     0.03     0.07 1.00      980     1098\n#&gt; sigma_days          0.07      0.03     0.01     0.12 1.00     1904     2113\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; ndt    45.91     32.10     2.39   115.89 1.00      740     1110\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\nCode\nplot(conditional_effects(fitrt2), points = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nCode\npp_check(fitrt2)"
  },
  {
    "objectID": "modules/models/index.html#revisiting-the-data",
    "href": "modules/models/index.html#revisiting-the-data",
    "title": "Models",
    "section": "Revisiting the data",
    "text": "Revisiting the data\n\n\nCode\npa &lt;- dat |&gt; \n  mutate(subject = fct_reorder(subject, reaction)) |&gt; \n  ggplot(aes(days, reaction)) +\n  geom_smooth(method = \"lm\", color = \"black\", linewidth = 0.5) +\n  geom_point() +\n  facet_wrap(\"subject\")\n\npb &lt;- dat |&gt; \n  ggplot(aes(days, reaction, group = subject)) +\n  geom_smooth(method = \"lm\", color = \"black\", linewidth = 0.5, se = FALSE)\n\n(pa | pb) + plot_layout(widths = c(6, 4), axis_titles = \"collect\")\n\n\n\n\n\n\n\n\nFigure 7: Scatterplots and a spaghetti plot of reaction times on days of sleep deprivation."
  },
  {
    "objectID": "modules/models/index.html#notation",
    "href": "modules/models/index.html#notation",
    "title": "Models",
    "section": "Notation",
    "text": "Notation\n\\[\n\\begin{aligned}\ny_{ij} &\\sim N\\left(\\beta_0 + \\gamma_{0j} + \\left(\\beta_1 + \\gamma_{1j}\\right)x_{ij}, \\sigma^2\\right), \\\\\n\\begin{bmatrix}\n  \\gamma_0 \\\\ \\gamma_1\n\\end{bmatrix} &\\sim\nMVN\\left(\n  \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\n  \\begin{pmatrix}\n    \\tau_0 & \\\\\n    \\rho &\\tau_1\n  \\end{pmatrix}\n\\right).\n\\end{aligned}\n\\tag{1}\\]\n\n\nCode\nfitml1 &lt;- brm(\n  reaction ~ days + (days | subject),\n  data = dat,\n  control = list(adapt_delta = .95),\n  file = here(\"models/introduction-ml-1\")\n)"
  },
  {
    "objectID": "modules/models/index.html#notation-1",
    "href": "modules/models/index.html#notation-1",
    "title": "Models",
    "section": "Notation",
    "text": "Notation\n\\[\n\\begin{align*}\ny_{ij} &\\sim N(\\beta_{0i} + \\beta_{1i}x_{ij}, \\sigma^2), \\\\\n\\beta_{0i} &= \\bar{\\beta}_0 + u_{0i}, \\\\\n\\beta_{1i} &= \\bar{\\beta}_1 + u_{1i}, \\\\\n\\begin{bmatrix}\n  u_{0i} \\\\ u_{1i}\n\\end{bmatrix} &\\sim MVN\\left(\n  \\begin{bmatrix}\n    0 \\\\ 0\n  \\end{bmatrix},\n  \\begin{pmatrix}\n    \\tau_0 \\ & \\\\\n    \\rho_{01} \\ &\\tau_1\n  \\end{pmatrix}\n\\right).\n\\tag{1}\n\\end{align*}\n\\tag{2}\\]\n\n\nCode\nfitml2 &lt;- brm(\n  bf(\n    reaction ~ b0 + b1*days,\n    b0 + b1 ~ 1 + (1 |s| subject),\n    nl = TRUE\n  ),\n  data = dat,\n  control = list(adapt_delta = .95),\n  file = here(\"models/introduction-ml-2\")\n)"
  },
  {
    "objectID": "modules/models/index.html#interpretation",
    "href": "modules/models/index.html#interpretation",
    "title": "Models",
    "section": "Interpretation",
    "text": "Interpretation\n\n\nCode\nkable(sm(fitml2))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nsd\nq2.5\nq97.5\npd\nrhat\ness_tail\n\n\n\n\nb_b0_Intercept\n267.77\n9.2\n249.4\n285.67\n1.00\n1\n2165\n\n\nb_b1_Intercept\n11.42\n2.1\n7.3\n15.65\n1.00\n1\n2747\n\n\nsd_subject__b0_Intercept\n34.06\n8.3\n21.1\n53.47\n1.00\n1\n2383\n\n\nsd_subject__b1_Intercept\n7.44\n1.9\n4.4\n11.58\n1.00\n1\n2592\n\n\ncor_subject__b0_Intercept__b1_Intercept\n0.18\n0.3\n-0.4\n0.75\n0.72\n1\n2021\n\n\nsigma\n25.98\n1.8\n22.8\n29.97\n1.00\n1\n2587"
  },
  {
    "objectID": "modules/models/index.html#priors-1",
    "href": "modules/models/index.html#priors-1",
    "title": "Models",
    "section": "Priors",
    "text": "Priors\n\n\nCode\nget_prior(fitml2)[,-c(5, 6, 9)]\n#&gt;                  prior class      coef   group nlpar lb  source\n#&gt;                 (flat)     b                      b0    default\n#&gt;                 (flat)     b Intercept            b0    default\n#&gt;                 (flat)     b                      b1    default\n#&gt;                 (flat)     b Intercept            b1    default\n#&gt;   lkj_corr_cholesky(1)     L                            default\n#&gt;                 (flat)     L           subject          default\n#&gt;  student_t(3, 0, 65.5)    sd                      b0  0 default\n#&gt;  student_t(3, 0, 65.5)    sd                      b1  0 default\n#&gt;                 (flat)    sd           subject    b0    default\n#&gt;                 (flat)    sd Intercept subject    b0    default\n#&gt;                 (flat)    sd           subject    b1    default\n#&gt;                 (flat)    sd Intercept subject    b1    default\n#&gt;  student_t(3, 0, 65.5) sigma                          0 default\n\n\n\nWhat do you think?"
  },
  {
    "objectID": "modules/sdt/index.html",
    "href": "modules/sdt/index.html",
    "title": "Signal Detection Models",
    "section": "",
    "text": "R packages\nlibrary(knitr)\nlibrary(tinytable)\nlibrary(bayesplot)\nlibrary(here)\nlibrary(scales)\nlibrary(ggdist)\nlibrary(distributional)\nlibrary(patchwork)\nlibrary(rstan)\nlibrary(brms)\nlibrary(tidyverse)\n\n# Some settings common to all modules\nsource(here(\"modules/_common.R\"))"
  },
  {
    "objectID": "modules/sdt/index.html#signal-detection-theory",
    "href": "modules/sdt/index.html#signal-detection-theory",
    "title": "Signal Detection Models",
    "section": "Signal Detection Theory",
    "text": "Signal Detection Theory\nSignal Detection Theory (SDT) is a common modeling framework for memory and perception. Calculating point estimates of equal variance Gaussian SDT parameters is easy using widely known formulas. More complex SDT models, such as the unequal variance SDT model, require more complicated modeling techniques. These models can be estimated using Bayesian (nonlinear and/or hierarchical) regression methods, which are sometimes difficult to implement in practice. In this tutorial, I describe how to estimate equal and unequal variance Gaussian SDT models as Generalized Linear Models for single participants, and for multiple participants simultaneously using hierarchical Bayesian models (sometimes called Generalized Linear Mixed Models).\nTo get started, consider a recognition memory experiment where participants are shown a series of images, some of which are new (participant has not seen before) and some of which are old (participant has seen before). Participants answer, for each item, whether they think they have seen the item before (“old!” response) or not (“new!” response). SDT models participants’ sensitivity—how well they can distinguish new and old images—and response criterion—their tendency, or bias, to respond “old!”—separately, and can therefore be enormously useful in modeling the participants’ cognitive processes. This logic applies to e.g. perception, where SDT was initially introduced in.\nThe conceptual basis of SDT (keeping with a memory task / metaphor) is that on each trial participants experience some inner “familiarity” (or memory strength) with the stimulus, which is hidden from the experimenter, or latent. The participants then decide, based on this familiarity signal and how far it exceeds their threshold for deciding that they’ve seen a stimulus, whether they have encountered the current stimulus previously (“old!”) or not (“new!”). I assume that readers are at least somewhat familiar with the basics of SDT, and will not discuss the underlying theory further. Classic introductions to SDT are Macmillan and Creelman (2005) and Green and Swets (1966)."
  },
  {
    "objectID": "modules/sdt/index.html#equal-variance-sdt-model",
    "href": "modules/sdt/index.html#equal-variance-sdt-model",
    "title": "Signal Detection Models",
    "section": "Equal Variance SDT Model",
    "text": "Equal Variance SDT Model\nWe first consider the common SDT model that assumes the participants’ familiarity distributions are two Gaussians with equal variances but possibly different means (i.e. previously seen items elicit a stronger familiarity signal, on average). This model is known as the EVSDT (equal variance SDT) model.\nWe estimate the model’s parameters for a single participant using three methods: “Manual” calculation of the point estimates using easy formulas translated to R code; estimating the model using a Bayesian Generalized Linear Model; and estimating the model using a Bayesian nonlinear model.\n\nExample data\nTo illustrate the EVSDT, we will use an example data frame from the sdtalt package (Wright 2011): “These are the data from the control group in Skagerberg and Wright’s study of memory conformity. Basically, this is the simplest old/new recognition memory design.” (Skagerberg and Wright 2008). We show six rows of these data in Table 1.\n\n\nCode\ndat &lt;- data.frame(\n  subno = c(53,53,53,53,54,54,54,54,55,55,55,\n            55,56,56,56,56,57,57,57,57,58,58,58,58,59,59,59,\n            59,60,60,60,60,61,61,61,61,62,62,62,62,63,63,\n            63,63,64,64,64,64,65,65,65,65,66,66,66,66,67,67,\n            67,67,68,68,68,68,69,69,69,69,70,70,70,70,71,71,\n            71,71,72,72,72,72,73,73,73,73,74,74,74,74,75,75,\n            75,75,76,76,76,76,77,77,77,77,78,78,78,78,79,\n            79,79,79,80,80,80,80,81,81,81,81,82,82,82,82,83,\n            83,83,83),\n  sayold = c(0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,\n             1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,\n             0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,\n             0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,\n             1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,\n             1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,\n             0,0,1,1),\n  isold = c(0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,\n            1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,\n            0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,\n            1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,\n            0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,\n            1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,\n            0,1,0,1),\n  n = c(33L,22L,20L,25L,39L,19L,14L,28L,36L,\n        16L,17L,31L,43L,9L,10L,38L,35L,18L,18L,29L,41L,\n        17L,12L,30L,46L,26L,7L,21L,38L,14L,15L,33L,42L,22L,\n        11L,25L,45L,25L,8L,22L,38L,11L,15L,36L,47L,7L,6L,\n        40L,39L,21L,14L,26L,28L,7L,25L,40L,33L,20L,20L,27L,\n        47L,3L,6L,44L,32L,12L,21L,35L,40L,15L,13L,32L,36L,\n        21L,17L,26L,31L,15L,22L,32L,40L,16L,13L,31L,43L,11L,\n        10L,36L,47L,19L,6L,28L,36L,13L,17L,34L,42L,16L,11L,\n        31L,36L,25L,17L,22L,35L,14L,18L,33L,49L,21L,4L,\n        26L,36L,15L,17L,32L,41L,20L,12L,27L,40L,22L,13L,25L)\n)\n\ndat &lt;- tibble(dat)\ndat &lt;- uncount(dat, weights = n)\n\nhead(dat) |&gt; \n  tt()\n\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                subno\n                sayold\n                isold\n              \n        \n        \n        \n                \n                  53\n                  0\n                  0\n                \n                \n                  53\n                  0\n                  0\n                \n                \n                  53\n                  0\n                  0\n                \n                \n                  53\n                  0\n                  0\n                \n                \n                  53\n                  0\n                  0\n                \n                \n                  53\n                  0\n                  0\n                \n        \n      \n    \n\n\n\n\nTable 1: Six rows of example recognition memory data\n\n\n\n\n\n\nCalculate point estimates\nWe begin by calculating the point estimates of the EVSDT parameters, separately for each participant in the data set. Before doing so, I note that this data processing is only required for manual calculation of the point estimates; the modeling methods described below take the raw data and therefore don’t require this step.\nFirst, we’ll compute for each trial whether the participant’s response was a hit, false alarm (fa), correct rejection (cr), or a miss. We’ll do this by creating a new variable, type:\n\n\nCode\nsdt &lt;- dat |&gt;\n  mutate(\n    type = \"hit\",\n    type = ifelse(isold == 1 & sayold == 0, \"miss\", type),\n    type = ifelse(isold == 0 & sayold == 0, \"cr\", type),\n    type = ifelse(isold == 0 & sayold == 1, \"fa\", type)\n  )\n\n\nThen we can simply count the numbers of these four types of trials for each participant, and put the counts on one row per participant.\n\n\nCode\nsdt &lt;- sdt |&gt;\n  count(subno, type) |&gt;\n  pivot_wider(names_from = type, values_from = n)\n\n\nFor a single subject, d’ can be calculated as the difference of the standardized hit and false alarm rates (Stanislaw and Todorov 1999):\n\\[\nd' = \\Phi^{-1}(HR) - \\Phi^{-1}(FAR)\n\\tag{1}\\]\n\\(\\Phi\\) is the normal cumulative distribution function, and is used to convert z scores into probabilities. \\(\\Phi^{-1}\\), the normal quantile function, converts a proportion (such as a hit rate or false alarm rate) into a z score. From here on, I refer to standardized hit and false alarm rates as zHR and zFAR, respectively. Response criterion c is calculated1 as:\n\\[\nc = -\\frac{\\Phi^{-1}(HR) + \\Phi^{-1}(FAR)}{2}\n\\tag{2}\\]\nWe can use R’s proportion to z-score function (\\(\\Phi^{-1}\\)), qnorm(), to calculate each participant’s d’ and c from the counts of hits, false alarms, misses and correct rejections.\n\n\nCode\nsdt &lt;- sdt |&gt;\n  mutate(\n    zhr = qnorm(hit / (hit + miss)),\n    zfa = qnorm(fa / (fa + cr)),\n    dprime = zhr - zfa,\n    crit = -(zhr + zfa) / 2\n  )\n\n\n\n\nCode\nround(sdt, 2) |&gt;\n  head() |&gt;\n  tt()\n\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                subno\n                cr\n                fa\n                hit\n                miss\n                zhr\n                zfa\n                dprime\n                crit\n              \n        \n        \n        \n                \n                  53\n                  33\n                  20\n                  25\n                  22\n                  0.08\n                  -0.31\n                  0.39\n                  0.12\n                \n                \n                  54\n                  39\n                  14\n                  28\n                  19\n                  0.24\n                  -0.63\n                  0.87\n                  0.19\n                \n                \n                  55\n                  36\n                  17\n                  31\n                  16\n                  0.41\n                  -0.47\n                  0.88\n                  0.03\n                \n                \n                  56\n                  43\n                  10\n                  38\n                   9\n                  0.87\n                  -0.88\n                  1.76\n                  0.01\n                \n                \n                  57\n                  35\n                  18\n                  29\n                  18\n                  0.30\n                  -0.41\n                  0.71\n                  0.06\n                \n                \n                  58\n                  41\n                  12\n                  30\n                  17\n                  0.35\n                  -0.75\n                  1.10\n                  0.20\n                \n        \n      \n    \n\n\n\n\nTable 2: Point estimates of EVSDT parameters\n\n\n\n\nThe sdt data frame (Table 2) now has point estimates of every participant’s d’ and c, and the quantities that went into calculating them. I show all parameters, and three participants’ implied EVSDT model in Figure 1.\n\n\n\n\n\n\n\n\nFigure 1: Top. The equal variance Gaussian signal detection model for three participants, based on manual calculation of the parameter’s point estimates. The two distributions are the noise distribution (dashed) and the signal distribution (solid); the vertical line represents the response criterion c. d’ is the distance between the peaks of the two distributions. Bottom. Scatterplot of all participants’ criteria and d’.\n\n\n\n\n\n\n\nEstimate parameters\nGeneralized Linear Models (GLM) are a powerful class of regression models that allow modeling binary outcomes, such as our “old!” / “new!” responses. In dat, each row (trial) can have one of two responses, “old!” (sayold = 1) or “new!” (sayold = 0). We use GLM to regress these responses on the stimulus type: On each trial, the to-be-judged stimulus can be either new (isold = 0) or old (isold = 1).\nWe assume that the outcomes are Bernoulli distributed (binomial with 1 trial), with probability \\(p_i\\) that \\(y_i = 1\\).\n\\[\ny_i \\sim Bernoulli(p_i)\n\\]\nBecause probabilities have upper and lower bounds at 1 and 0, we map p to a “linear predictor” \\(\\eta\\) with a link function, and model \\(\\eta\\) with an additive combination of predictors. If this link function is probit, we have a “probit model”2:\n\\[\np_i = \\Phi(\\eta_i)\n\\]\n\\(\\Phi\\) is again the normal distribution function and maps z scores to probabilities. We then model \\(\\eta\\) on an intercept and a slope:\n\\[\n\\eta_i = \\beta_0 + \\beta_1\\mbox{isold}_i\n\\]\nGiven this parameterization, the intercept of the model (\\(\\beta_0\\)) will indicate the (probit of) the probability of responding “old!”, when all predictors are zero. When isold, our predictor, is “sum-to-zero” coded as (e.g.) -0.5 and 0.5 for new and old items respectively, the intercept corresponds to -c (see Equation 2). We therefore ensure that isold is appropriately coded\n\n\nCode\ndat$isold &lt;- factor(\n  dat$isold, \n  levels = 0:1, \n  labels = c(\"new\", \"old\")\n)\ncontrasts(dat$isold) &lt;- c(-0.5, 0.5)\ncontrasts(dat$isold)\n#&gt;     [,1]\n#&gt; new -0.5\n#&gt; old  0.5\n\n\nThe slope of the model (\\(\\beta_1\\)) is the difference in z-scored probabilities of saying “old!” between old and new items. Specifically, since new items are coded as -0.5 and old items as 0.5, \\(d' = \\beta_1\\) (see Equation 1).\nThe connection between SDT models and GLM is discussed in detail by DeCarlo (1998). Two immediate benefits of thinking about SDT models in a GLM framework is that we can now easily include predictors on c and d’, and estimate SDT models with varying coefficients using hierarchical modeling methods (DeCarlo 2010; Rouder and Lu 2005). This latter point means that we can easily fit the models for multiple participants (and items!) simultaneously, while at the same time pooling information across participants (and items). We will return to this point below.\nBecause we wrote the SDT model as a GLM, we have a variety of software options for estimating the model. For this simple model, you could just use base R’s glm(). Here, we use the Bayesian regression modeling R package brms (Bürkner 2017; Stan Development Team 2016a), because its model formula syntax extends seamlessly to more complicated models that we will discuss later. We can estimate the GLM with brms’s brm() function, by providing as arguments a model formula in brms syntax (identical to base R model syntax for simple models), an outcome distribution with a link function, and a data frame.\nbrms’s model syntax uses variable names from the data. We regress the binary sayold responses on the binary isold predictor with the following formula: sayold ~ isold. The distribution of the outcomes is specified with family argument. To specify the bernoulli distribution with a probit link function, we use family = bernoulli(link=\"probit\"). We will only model the first participant’s data (number 53), and therefore specify the data with data = filter(dat, subno==53).\nThe brm() function also allows specifying prior distributions on the parameters, but for this introductory discussion we omit discussion of priors. Finally, we specify file, to save the model to a file so that we don’t have to re-estimate the model whenever we restart R.\nPutting these pieces together, we estimate the SDT model as a probit GLM, using data stored in dat, for subject 53 only, with the following function:\n\n\nCode\nevsdt_1 &lt;- brm(\n  sayold ~ isold,\n  family = bernoulli(link = \"probit\"),\n  data = filter(dat, subno == 53),\n  file = here(\"models/sdtmodel1-1\")\n)\n\n\nThe estimated model is saved in evsdt_1, whose summary() method returns a numerical summary of the estimated parameters along with some information and diagnostics about the model:\n\n\nCode\nsummary(evsdt_1)\n#&gt;  Family: bernoulli \n#&gt;   Links: mu = probit \n#&gt; Formula: sayold ~ isold \n#&gt;    Data: filter(confcontr, subno == 53) (Number of observations: 100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    -0.11      0.13    -0.36     0.12 1.00     3650     2786\n#&gt; isold1        0.40      0.26    -0.14     0.90 1.00     3706     2265\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nThe regression parameters (Intercept (\\(c = -\\beta_0\\)) and isold (\\(d' = \\beta_1\\))) are described in the “Regression Coefficients” table in the above output. Estimate reports the posterior means, which are comparable to maximum likelihood point estimates, and Est.Error reports the posterior standard deviations, which are comparable to standard errors. The next two columns report the parameter’s 95% Credible Intervals (CIs). The estimated parameters’ means match the point estimates we calculated by hand (see table above.)\nIn fact, the posterior modes will exactly correspond to the maximum likelihood estimates, if we use uniform priors. The posterior density of d’ and c, for participant 53, is illustrated in Figure 2: The maximum likelihood estimate is spot on the highest peak of the posterior density.\n\n\n\n\n\n\n\n\nFigure 2: The (approximate) joint posterior density of subject 53’s SDT parameters. Lighter yellow colors indicate higher posterior density. The red dot indicates the ‘manually’ calculated MLE point estimate of d’.\n\n\n\n\n\nFigure 2 raises some interesting questions: What happens if we ignore the uncertainty in the estimated parameters (the colorful cloud of decreasing plausibility around the peak)? The answer is that not much happens for inference about averages by ignoring the subject-specific parameters’ uncertainty, if the design is balanced across participants. But what will happen if we use the point estimates as predictors in some other regression, while ignoring their uncertainty? What are the implications of having very uncertain estimates? Should we trust the mode?\nIn any case, I hope the above has illustrated that the equal variance Gaussian SDT parameters are easy to obtain within the GLM framework. Next, we describe how to estimate the SDT model using brms’ nonlinear modeling syntax.\n\n\nEstimate parameters with a nonlinear model\nHere, we write the EVSDT model in a similar way as the GLM above, but simply flip the criterion and d’. To do that we need to use brms’ nonlinear modelling syntax. This parameterization will give c directly, without the need to flip the estimated parameter value. Although conceptually similar to above, and not necessarily useful by itself, it might be useful to fit this small variation of the above GLM to get familiar with brms’ nonlinear modeling syntax. We write the model as follows (DeCarlo 1998):\n\\[\np_i = \\Phi(d'\\mbox{isold}_i - c)\n\\]\nThis model gives us direct estimates of c and d’. Writing and estimating nonlinear models can be considerably more involved than fitting GLMs. Accordingly, the code below is a bit more complicated. The key point here is, however, that using brms, we can estimate models that may be nonlinear without deviating too far from the basic formula syntax.\nFirst, we’ll specify the model using the bf() function:\n\n\nCode\nm2 &lt;- bf(\n  sayold ~ Phi(dprime * isold - c),\n  dprime ~ 1, c ~ 1,\n  nl = TRUE\n)\n\n\nLet’s walk through this code line by line. On the first line, we specify the model of sayold responses. Recall that we are modeling the responses as Bernoulli distributed (this will be specified as an argument to the estimation function, below). Therefore, the right-hand side of the first line (after ~) is a model of the probability parameter (\\(p_i\\)) of the Bernoulli distribution.\nThe two unknown parameters in the model, d’ and c, are estimated from data, as indicated by the second line (i.e. dprime ~ 1). The third line is required to tell brms that the model is nonlinear. To further understand how to write models with brms’ nonlinear modeling syntax, see (vignette(\"brms_nonlinear\", package = \"brms\")) (or here).\nBecause the parameters of nonlinear models can be more difficult to estimate, brms requires the user to set priors when nl = TRUE. We set somewhat arbitrary priors on dprime and c (the scale parameter is standard deviation, not variance):\n\n\nCode\nPriors &lt;- c(\n  prior(normal(.5, 3), nlpar = \"dprime\"),\n  prior(normal(0, 1.5), nlpar = \"c\")\n)\n\n\nAfter specifying the model and priors, fitting the model is done again using brm() with only a few adjustments: because we specified the link function inside bf() (the Phi() function), we should explicitly set link=\"identity\" in the family argument. Because nonlinear models are trickier to estimate, we also adjust the underlying Stan sampler’s adapt_delta parameter (this will make the MCMC a little slower but will return less noisy results).\n\n\nCode\nevsdt_2 &lt;- brm(\n  m2,\n  family = bernoulli(link = \"identity\"),\n  data = filter(dat, subno == 53),\n  prior = Priors,\n  control = list(adapt_delta = .99),\n  file = here(\"models/sdtmodel1-2\")\n)\n\n\nNotice that we now entered m2 as the first argument, whereas with the first model, we simply wrote the formula inside the brm() function. These two ways are equivalent, but because this model is more complicated, I saved it into a variable as a separate line of code. We then compare the two models’ estimated parameters in Table 3. Recall that the latter model directly reports the standardized false alarm rate (c).\n\n\nCode\nbind_rows(\n  as_tibble(\n    posterior_summary(evsdt_1)[1:2,] |&gt; \n      as.data.frame() |&gt; \n      rownames_to_column()\n  ),\n  as_tibble(\n    posterior_summary(evsdt_2)[c(2, 1),] |&gt; \n      as.data.frame() |&gt; \n      rownames_to_column()),\n  .id = \"Model\"\n) |&gt; \n  tt()\n\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Model\n                rowname\n                Estimate\n                Est.Error\n                Q2.5\n                Q97.5\n              \n        \n        \n        \n                \n                  1\n                  b_Intercept       \n                  -0.11\n                  0.13\n                  -0.36\n                  0.12\n                \n                \n                  1\n                  b_isold1          \n                   0.40\n                  0.26\n                  -0.14\n                  0.90\n                \n                \n                  2\n                  b_c_Intercept     \n                   0.12\n                  0.13\n                  -0.14\n                  0.37\n                \n                \n                  2\n                  b_dprime_Intercept\n                   0.40\n                  0.26\n                  -0.11\n                  0.91\n                \n        \n      \n    \n\n\n\n\nTable 3: Parameter estimates from EVSDT models fitted to subject number 53.\n\n\n\n\nThe results are very similar, but note that priors were included only in the nonlinear syntax model. The only real difference is that the MCMC algorithm explored evsdt_2’s posterior less efficiently, as shown by the smaller effective sample sizes (..._ESS) for both parameters. This means that the random draws from the posterior distribution, for evsdt_2, have greater autocorrelation, and therefore we should possibly draw more samples for more accurate inference. The posterior distributions obtained with the 2 methods are shown in Figure 3.\n\n\nCode\np2 &lt;- as_draws_df(evsdt_2)[, 1:2] |&gt;\n  ggplot(aes(b_dprime_Intercept, b_c_Intercept)) +\n  scale_fill_viridis_c() +\n  stat_density_2d(aes(fill = after_stat(density)),\n                  geom = \"raster\", contour = F, show.legend = FALSE, n = 301\n  ) +\n  geom_point(data = sdt[1, ], aes(x = dprime, y = crit), col = \"red\", size = 2) +\n  coord_cartesian(expand = 0) +\n  labs(x = \"d'\", y = \"Criterion\") +\n  theme(aspect.ratio = 1)\npst1 &lt;- as_draws_df(evsdt_1, pars = \"b_\") |&gt;\n  rename(c = b_Intercept, dprime = b_isold1) |&gt;\n  mutate(c = -c)\npst2 &lt;- as_draws_df(evsdt_2, pars = \"b_\") |&gt;\n  rename(c = b_c_Intercept, dprime = b_dprime_Intercept)\np3 &lt;- bind_rows(pst1, pst2, .id = \"Model\") |&gt;\n  mutate(Model = ifelse(Model == 1, \"GLM\", \"Nonlinear\")) |&gt;\n  gather(parameter, value, c:dprime) |&gt;\n  ggplot(aes(x = value, fill = Model, col = Model)) +\n  scale_fill_brewer(palette = \"Set1\") +\n  stat_density(\n    geom = \"area\", position = position_identity(),\n    alpha = .4\n  ) +\n  scale_y_continuous(expand = expansion(c(0, .1))) +\n  facet_wrap(\"parameter\", strip.position = \"bottom\", scales = \"free\") +\n  theme(\n    legend.position = \"none\",\n    strip.text = element_text(hjust = 0.5, size = rel(1)),\n    strip.background = element_blank(),\n    axis.title.x = element_blank(),\n    strip.placement = \"outside\",\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank()\n  )\n(p1 + labs(title = \"GLM\") | p2 + labs(title = \"Nonlinear syntax\")) /\n  p3 +\n  plot_layout(heights = c(6.5, 3.5))\n\n\n\n\n\n\n\n\nFigure 3: Top row: The joint posterior density of subject 53’s SDT parameters, estimated with the GLM and the nonlinear model. Lighter yellow colors indicate higher posterior density. The red dot indicates the sample mean d’ that was calculated ‘manually’. Bottom row: The marginal posterior densities of c and dprime from GLM (red) and nonlinear (blue) models.\n\n\n\n\n\nThere is little benefit in using the second, “nonlinear” parameterization of EVSDT in this case. However, it is useful to study this simpler case to make it easier to understand how to fit more complicated nonlinear models with brms."
  },
  {
    "objectID": "modules/sdt/index.html#estimate-parameters-with-aggregated-data",
    "href": "modules/sdt/index.html#estimate-parameters-with-aggregated-data",
    "title": "Signal Detection Models",
    "section": "Estimate parameters with aggregated data",
    "text": "Estimate parameters with aggregated data\nIt is sometimes useful, especially with very large data, to aggregate data to counts for each combination of all categorical predictors. For example, to aggregate the current data\n\n\nCode\ndat\n#&gt; # A tibble: 3,100 × 3\n#&gt;    subno sayold isold\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;\n#&gt;  1    53      0 new  \n#&gt;  2    53      0 new  \n#&gt;  3    53      0 new  \n#&gt;  4    53      0 new  \n#&gt;  5    53      0 new  \n#&gt;  6    53      0 new  \n#&gt;  7    53      0 new  \n#&gt;  8    53      0 new  \n#&gt;  9    53      0 new  \n#&gt; 10    53      0 new  \n#&gt; # ℹ 3,090 more rows\n\n\n\nInterim discussion\n\nFitting one subject’s EVSDT model with different methods\nWe have now estimated the equal variance Gaussian SDT model’s parameters for one subject’s data using three methods: Calculating point estimates manually, with a probit GLM, and with a probit model using brms’ nonlinear modeling syntax. The main difference between these methods, so far, is that the modeling methods provide estimates of uncertainty in the parameters, whereas the manual calculation does not. This point leads us directly to hierarchical models (Rouder and Lu 2005; Rouder et al. 2007), which we discuss next.\nHowever, there are other, perhaps more subtle, benefits of using a regression model framework for estimating SDT models. There is something to be said, for example, about the fact that the models take the raw data as input. ‘Manual’ calculation involves, well, manual computation of values, which may be more error prone than using raw data. This is especially clear if the modeling methods are straightforward to apply: I hope to have illustrated that with R and brms (Bürkner 2017), Bayesian modeling methods are easy to apply and accessible to a wide audience.\nMoving to a modeling framework will also allow us to include multiple sources of variation, such as heterogeneity across items and participants, through crossed “random” effects (Rouder et al. 2007), and covariates that we think might affect the SDT parameters. By changing the link function, we can also easily use other distributions, such as logistic, to represent the signal and noise distributions (DeCarlo 1998, 2010).\n\n\nPrior distribution\nFinally, priors. Newcomers to the Bayesian modeling framework might object to the use of prior distributions, and think that they are unduly biasing the results. However, moderately informative priors usually have far less of an influence on inference than newcomers might assume. Above, we specified the GLM with practically no prior information; if you are reluctant to include existing knowledge into your model, feel free to leave it out. Things are, unfortunately, a little more complicated with the nonlinear modeling functions: The posterior geometry might be funky (technical term), in which case the priors could mainly serve to nudge the posterior samples to be drawn from sensible parameter values.\nFurther, priors can be especially useful in estimating SDT models: If participants’ hit or false alarm rates are 0 or 1–a fairly common scenario–mild prior information can be used in a principled manner to release the estimated quantities from the hostile captivity of the boundary values. Prior literature has discussed various corrections to 0 and 1 rates (Stanislaw and Todorov 1999). However, Bayesian priors can take care of these edge cases in a more principled manner."
  },
  {
    "objectID": "modules/sdt/index.html#evsdt-for-multiple-participants",
    "href": "modules/sdt/index.html#evsdt-for-multiple-participants",
    "title": "Signal Detection Models",
    "section": "EVSDT for multiple participants",
    "text": "EVSDT for multiple participants\nAbove, we obtained parameter estimates of the EVSDT model for a single subject using three methods: Manual calculation of point estimates (Stanislaw and Todorov 1999), estimating the model as a GLM (Generalized Linear Model; DeCarlo (1998)), and estimating the model as a GLM using brms’ nonlinear modeling syntax (Bürkner 2017).\nHowever, researchers are usually not as interested in the specific subjects that happened to participate in their experiment, as they are in the population of potential subjects. Therefore, we are unsatisfied with parameters which describe only the subjects that happened to participate in our study: The final statistical model should have parameters that estimate features of the population of interest.\nBroadly, there are two methods for obtaining these “population level” parameters. By far the most popular method is to summarise the manually calculated subject-specific point estimates of d’ and c with their sample means and standard deviations. From these, we can calculate standard errors, t-tests, confidence intervals, etc. Another method–which I hope to motivate here–is to build a bigger model that estimates subject-specific and population-level parameters simultaneously. We call this latter method “hierarchical” or “multilevel” modeling (Gelman and Hill 2007; Rouder and Lu 2005). In this section, I show how to obtain population-level EVSDT parameters with these two methods, using the R programming language and the brms R package (R Core Team 2017; Bürkner 2017).\n\nPopulation-level EVSDT Model\nWe now use these data to estimate the population-level EVSDT parameters using two methods: Manual calculation and hierarchical modeling. For hierarchical modeling, I provide R & brms code to estimate the model as a Generalized Linear Mixed Model (GLMM). I also show how to estimate the GLMM with brms’ nonlinear modeling syntax.\n\nEstimation by summarizing subjects’ point estimates\nAbove we calculated d’ and c for every participant in the sample:\n\n\n\nSample participants’ SDT parameters\n\n\nsubno\ncr\nfa\nhit\nmiss\nzhr\nzfa\ndprime\ncrit\n\n\n\n\n53\n33\n20\n25\n22\n0.08\n-0.31\n0.39\n0.12\n\n\n54\n39\n14\n28\n19\n0.24\n-0.63\n0.87\n0.19\n\n\n55\n36\n17\n31\n16\n0.41\n-0.47\n0.88\n0.03\n\n\n56\n43\n10\n38\n9\n0.87\n-0.88\n1.76\n0.01\n\n\n57\n35\n18\n29\n18\n0.30\n-0.41\n0.71\n0.06\n\n\n58\n41\n12\n30\n17\n0.35\n-0.75\n1.10\n0.20\n\n\n\n\n\nWe can therefore calculate sample means and standard errors for both parameters using these individual-specific values. Here’s one way to do it:\n\n\nCode\nsdt_sum &lt;- select(sdt, subno, dprime, crit) |&gt; # Select these variables only\n  gather(parameter, value, -subno) |&gt; # Convert data to long format\n  group_by(parameter) |&gt; # Prepare to summarise on these grouping variables\n  # Calculate summary statistics for grouping variables\n  summarise(n = n(), mu = mean(value), sd = sd(value), se = sd / sqrt(n))\n\n\n\nAverage EVSDT parameters\n\n\nparameter\nn\nmu\nsd\nse\n\n\n\n\ncrit\n31\n0.13\n0.25\n0.04\n\n\ndprime\n31\n1.09\n0.50\n0.09\n\n\n\n\n\nThe sample means (mu) are estimates of the population means, and the sample standard deviations (sd) divided by \\(\\sqrt{N subjects}\\) are estimated standard deviations of the respective sampling distributions: the standard errors (se). Because the standard deviations of the sampling distributions are unknown and therefore estimated from the data, researchers almost always substitute the Gaussian sampling distribution with a Student’s t-distribution to obtain p-values and confidence intervals (i.e. we run t-tests, not z-tests.)\nNote that this method involves calculating point estimates of unknown parameters (the subject-specifc parameters), and then summarizing these parameters with additional models. In other words, we first fit N models with P parameters each (N = number of subjects, P = 2 parameters), and then P more models to summarise the subject-specific models.\nNext, we’ll use hierarchical regression3 methods to obtain subject-specific and population-level parameters in one single step.\n\n\nEstimation with a hierarchical model (GLMM)\nWe can estimate the EVSDT model’s parameters for every subject and the population average in one step using a Generalized Linear Mixed Model (GLMM). Gelman and Hill (2007) and McElreath (2016) are good general introductions to hierarchical models. Rouder and Lu (2005) and Rouder et al. (2007) discuss hierarchical modeling in the context of signal detection theory.\nThis model is very much like the GLM discussed in Part 1, but now the subject-specific d’s and cs are modeled as draws from a multivariate normal distribution, whose (“hyper”)parameters describe the population-level parameters. We subscript subjects’ parameters with j, rows in data with i, and write the model as:\n\\[y_{ij} \\sim Bernoulli(p_{ij})\\] \\[\\Phi(p_{ij}) = \\beta_{0j} + \\beta_{1j}\\mbox{isold}_{ij}\\]\nThe outcomes \\(y_{ij}\\) are 0 if participant j responded “new!” on trial i, 1 if they responded “old!”. The probability of the “old!” response for row i for subject j is \\(p_{ij}\\). We then write a linear model on the probits (z-scores; \\(\\Phi\\), “Phi”) of ps. The subject-specific intercepts (recall, \\(\\beta_0\\) = -zFAR) and slopes (\\(\\beta_1\\) = d’) are described by multivariate normal with means and a covariance matrix for the parameters.\n\\[\n\\left[\\begin{array}{c}\n\\beta_{0j} \\\\ \\beta_{1j}\n\\end{array}\\right]\n\\sim MVN(\n\\left[\\begin{array}{c}\n\\mu_{0} \\\\ \\mu_{1}\n\\end{array}\\right],\n\\Sigma\n)\n\\]\nThe means \\(\\mu_0\\) and \\(\\mu_1\\), i.e. the population-level parameters, can be interpreted as parameters “for the average person” (Bolger and Laurenceau 2013). The covariance matrix \\(\\Sigma\\) contains the subject-specific parameters’ (co)variances, but I find it easier to discuss standard deviations (I call them \\(\\tau\\), “tau”) and correlations. The standard deviations describe the between-person heterogeneities in the population. The correlation term, in turn, describes the covariance of the d’s and cs: Are people with higher d’s more likely to have higher cs?\nThis model is therefore more informative than running multiple separate GLMs, because it models the covariances as well, answering important questions about heterogeneity in effects.\nThe brms syntax for this model is very similar to the one-subject model. We have five population-level parameters to estimate. The intercept and slope describe the means: In R and brms modeling syntax, an intercept is indicated with 1 (and can be omitted because it is automatically included, here I include it for clarity), and slope of a variable by including that variable’s name in the data. To include the two regression coefficients, we write sayold ~ 1 + isold.\nHowever, we also have three (co)variance parameters to estimate. To include subject-specific parameters (recall, subjects are indexed by subno variable in data d), and therefore the (co)variance parameters, we expand the formula to sayold ~ 1 + isold + (1 + isold | subno). The part in the parentheses describes subno specific intercepts (1) and slopes of isold. Otherwise, the call to brm() is the same as with the GLM in Part 1:\n\n\nCode\nevsdt_glmm &lt;- brm(sayold ~ 1 + isold + (1 + isold | subno),\n                  family = bernoulli(link = \"probit\"),\n                  data = dat,\n                  cores = 4,\n                  file = here(\"models/sdtmodel2-1\")\n)\n\n\nLet’s take a look at the GLMM’s estimated parameters. First, direct your eyes to the “Population-Level Effects” table in the below output. These two parameters are the mean -criterion (Intercept, \\(\\mu_0\\)) and d’ (isold, \\(\\mu_1\\)). Recall that we are looking at numerical summaries of (random samples from) the parameters’ posterior distributions: Estimate is the posterior mean.\n\n\nCode\nsummary(evsdt_glmm)\n#&gt;  Family: bernoulli \n#&gt;   Links: mu = probit \n#&gt; Formula: sayold ~ 1 + isold + (1 + isold | subno) \n#&gt;    Data: confcontr (Number of observations: 3100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Multilevel Hyperparameters:\n#&gt; ~subno (Number of levels: 31) \n#&gt;                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sd(Intercept)             0.21      0.04     0.13     0.30 1.00     1635     2594\n#&gt; sd(isold1)                0.40      0.09     0.25     0.60 1.00     1466     2074\n#&gt; cor(Intercept,isold1)     0.11      0.26    -0.41     0.58 1.00     1670     2291\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    -0.13      0.05    -0.22    -0.04 1.00     2378     2565\n#&gt; isold1        1.06      0.09     0.89     1.24 1.00     2189     2498\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe can then compare the Population-level mean parameters of this model to the sample summary statistics we calculated above. The posterior means map nicely to the calculated means, and the posterior standard deviations match the calculated standard errors.\nThese mean effects are visualized as a colored density in the left panel of Figure 4. However, the GLMM also returns estimates of the parameters’ (co)variation in the population. Notice that we also calculated the sample standard deviations, which also provide this information, but we have no estimates of uncertainty in those point estimates. The GLMM, on the other hand, provides full posterior distributions for these parameters.\nThe heterogeneity parameters are reported in the “Group-Level Effects”4 table, above. We find that the criteria are positively correlated with d’s (recall that Intercept = -c). The two standard deviations are visualized in the right panel of Figure 4.\n\n\n\n\n\n\n\n\nFigure 4: Left panel: The (approximate) joint posterior density of the average d’ and criterion. Lighter values indicate higher posterior probability. Right panel: The (approximate) joint posterior density of the standard deviations of d’s and criteria in the population. In both panels, the red dot indicates the ‘manually’ calculated sample statistics.\n\n\n\n\n\nIt is evident in Figure 4 that the sample means approximately match the posterior mode, but less so for the sample standard deviations, which are far from the peak of the standard deviations’ posterior distribution. By ignoring the uncertainty in the subject-specific parameters, the ‘manual calculation’ method has over-estimated the heterogeneity of d’s and cs in the population, in comparison to the GLMM which takes the subject-specific parameters’ uncertainty into account.\nThis idea has further implications, revealed by investigating the two methods’ estimates of the subject-specific parameters. Recall that the manual calculation method involved estimating (the point estimates of) a separate model for each participant. A hierarchical model considers all participants’ data simultaneously, and the estimates are allowed to inform each other via the shared prior distribution (right hand side of the equation repeated from above):\n\\[\n\\left[\\begin{array}{c}\n\\beta_{0j} \\\\ \\beta_{1j}\n\\end{array}\\right]\n\\sim N(\n\\left[\\begin{array}{c}\n\\mu_{0} \\\\ \\mu_{1}\n\\end{array}\\right],\n\\Sigma\n)\n\\]\nThis “partial pooling” of information (Gelman and Hill 2007) is evident when we plot the GLMM’s subject-specific parameters in the same scatterplot with the N models method (calculating point estimates separately for everybody; Figure 5).\n\n\n\n\n\n\n\n\nFigure 5: Subject-specific d’s and criteria as given by the independent models (filled circles), and as estimated by the hierarchical model (empty circles). The hierarchical model shrinks the estimated parameters toward the overall mean parameters (red dot). This shrinkage is greater for more extreme parameter values: Each subject-specific parameter is a compromise between that subject’s data, and other subjects in the sample. As the data points per subject, or the heterogeneity between subjects, increases, this shrinkage will decrease. The hierarchical model essentially says ‘People are different, but not that different’.\n\n\n\n\n\nWe see that estimating the EVSDT model for many individuals simultaneously with a hierarchical model is both easy to fit and informative. Specifically, it is now easy to include predictors on the parameters, and answer questions about possible influences on d’ and c.\n\n\nIncluding predictors\nDo the EVSDT parameters differ between groups of people? How about between conditions, within people? To answer these questions, we would repeat the manual calculation of parameters as many times as needed, and then draw inference by “submitting” the subject-specific parameters to e.g. an ANOVA model. The GLMM approach affords a more straightforward solution to including predictors: We simply add parameters to the regression model.\nFor example, if there were two groups of participants, indexed by variable group in data, we could extend the brms GLMM syntax to (the ... is a placeholder for other arguments used above, I also dropped the 1 for clarity because they are implicitly included):\n\n\nCode\nbrm(sayold ~ isold * group + (isold | subno), ...)\n\n\nThis model would have two additional parameters: group would describe the difference in c between groups, and the interaction term isold:group would describe the difference in d’ between groups. If, on the other hand, we were interested in the effects of condition, a within-subject manipulation, we would write:\n\n\nCode\nbrm(sayold ~ isold * condition + (isold * condition | subno), ...)\n\n\nWith small changes, this syntax extends to “mixed” between- and within-subject designs.\n\n\nEstimation with a GLMM (nonlinear syntax)\nHere, I briefly describe fitting the above GLMM with brms’ nonlinear model syntax. The basic model is a straightforward reformulation of the single-subject case in Part 1 and the GLMM described above:\n\\[p_{ij} = \\Phi(d'_j\\mbox{isold}_{ij} - c_{j})\\]\nThe varying d-primes and criteria are modeled as multivariate normal, as with the GLMM. It turns out that this rather complex model is surprisingly easy to fit with brms. The formula is very similar to the single-subject nonlinear model but we tell bf() that the dprimes and criteria should have subject-specific parameters, as well as population-level parameters.\nAbove, with the GLMM, subject-specific effects were given by (1 + isold | subno). With the nonlinear modeling syntax, we specify varying effects across multiple parameters using |s| instead of | to tell brms that these parameters should be within one covariance matrix. This syntax gives us the “correlated random effects signal detection model” discussed in Rouder et al. (2007). Apart from the syntax, the model is the same as the GLMM above, but the sign of the intercept is flipped.\n\n\nCode\nglmm2 &lt;- bf(sayold ~ Phi(dprime * isold - c),\n            dprime ~ 1 + (1 | s | subno),\n            c ~ 1 + (1 | s | subno),\n            nl = TRUE\n)\n\n\nThis time, we’ll set priors on the mean parameters and on the (co)variance parameters. Of note is the lkj(4) parameter which slightly regularizes the d’-criterion correlation toward zero (McElreath 2016; Stan Development Team 2016b).\n\n\nCode\nPriors &lt;- c(\n  prior(normal(0, 3), nlpar = \"dprime\", lb = 0),\n  prior(normal(0, 3), nlpar = \"c\"),\n  prior(student_t(10, 0, 1), class = \"sd\", nlpar = \"dprime\"),\n  prior(student_t(10, 0, 1), class = \"sd\", nlpar = \"c\"),\n  prior(lkj(4), class = \"cor\")\n)\n\n\nWe fit the model as before, but adjust the control argument, and set inits to zero to improve sampling efficiency (thanks to Tom Wallis for this tip):\n\n\nCode\nevsdt_glmm2 &lt;- brm(glmm2,\n                   family = bernoulli(link = \"identity\"),\n                   data = dat,\n                   prior = Priors,\n                   control = list(adapt_delta = .99),\n                   cores = 4, inits = 0,\n                   file = here(\"models/sdtmodel2-2\")\n)\n\n\nAlthough this model samples less efficiently than the first GLMM formulation, we (unsurprisingly) observe similar results.\n\n\nCode\nsummary(evsdt_glmm)\n#&gt;  Family: bernoulli \n#&gt;   Links: mu = probit \n#&gt; Formula: sayold ~ 1 + isold + (1 + isold | subno) \n#&gt;    Data: confcontr (Number of observations: 3100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Multilevel Hyperparameters:\n#&gt; ~subno (Number of levels: 31) \n#&gt;                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sd(Intercept)             0.21      0.04     0.13     0.30 1.00     1635     2594\n#&gt; sd(isold1)                0.40      0.09     0.25     0.60 1.00     1466     2074\n#&gt; cor(Intercept,isold1)     0.11      0.26    -0.41     0.58 1.00     1670     2291\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    -0.13      0.05    -0.22    -0.04 1.00     2378     2565\n#&gt; isold1        1.06      0.09     0.89     1.24 1.00     2189     2498\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\nsummary(evsdt_glmm2)\n#&gt;  Family: bernoulli \n#&gt;   Links: mu = identity \n#&gt; Formula: sayold ~ Phi(dprime * isold - c) \n#&gt;          dprime ~ 1 + (1 | s | subno)\n#&gt;          c ~ 1 + (1 | s | subno)\n#&gt;    Data: confcontr (Number of observations: 3100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Multilevel Hyperparameters:\n#&gt; ~subno (Number of levels: 31) \n#&gt;                                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sd(dprime_Intercept)                  0.39      0.08     0.25     0.57 1.00     1636     2608\n#&gt; sd(c_Intercept)                       0.21      0.04     0.14     0.30 1.00     1783     2655\n#&gt; cor(dprime_Intercept,c_Intercept)    -0.08      0.21    -0.48     0.35 1.00     1763     2325\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; dprime_Intercept     1.06      0.09     0.89     1.23 1.00     1977     2337\n#&gt; c_Intercept          0.13      0.05     0.04     0.22 1.00     2188     2293\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nFor technical reasons, each parameter in evsdt_glmm2 has a _Intercept suffix, but the results are the same across the two ways of writing this model.\n\n\n\nInterim discussion\nHierarchical modeling techniques have several advantages over traditional methods, such as (M)ANOVA, for modeling data with within-subject manipulations and repeated measures. For example, many models that previously required using parameters from subject-specific models as inputs to another model can be modeled within a single hierarchical model. Hierarchical models naturally account for unbalanced data, and allow incorporating continuous predictors and discrete outcomes. In the specific context of SDT, we observed that hierarchical models also estimate important parameters that describe possible between-person variability in parameters in the population of interest.\nFrom casual observation, it appears that hierarchical models are becoming more widely used. Many applied papers now analyze data using multilevel models, instead of rm-ANOVA, suggesting that there is demand for these models within applied research contexts. Conceptualizing more complex, possibly nonlinear models as hierarchical models should then afford a more unified framework for data analysis. Furthermore, by including parameters for between-person variability, these models allow researchers to quantify the extent to which their effects of interest vary and, possibly, whether these effects hold for everybody in the population."
  },
  {
    "objectID": "modules/sdt/index.html#unequal-variance-gaussian-sdt-model",
    "href": "modules/sdt/index.html#unequal-variance-gaussian-sdt-model",
    "title": "Signal Detection Models",
    "section": "Unequal variance Gaussian SDT model",
    "text": "Unequal variance Gaussian SDT model\nNext, I extend the discussion to rating tasks to show how unequal variance Gaussian SDT (UVSDT) models can be estimated with with Bayesian methods, using R and the brms package (Bürkner 2017; R Core Team 2017). As above, we first focus on estimating the model for a single participant, and then discuss hierarchical models for multiple participants.\n\nExample data: Rating task\nWe begin with a brief discussion of the rating task, with example data from Decarlo (2003). Above, we discussed signal detection experiments where the item was either old or new, and participants provided binary “old!” or “new!” responses. Here, we move to a slight modification of this task, where participants are allowed to express their certainty: On each trial, the presented item is still old or new, but participants now rate their confidence in whether the item was old or new. For example, and in the data below, participants can answer with numbers indicating their confidence that the item is old: 1 = Definitely new, …, 6 = Definitely old.\nOne interpretation of the resulting data is that participants set a number of criteria for the confidence ratings, such that greater evidence is required for 6-responses, than 4-responses, for example. That is, there will be different criteria for responding “definitely new”, “maybe new”, and so forth. However, the participant’s underlying discriminability should remain unaffected.\nThe example data is shown in a summarised form below (counts of responses for each confidence bin, for both old (isold = 1) and new trial types (Decarlo 2003)):\n\n\nCode\ndsum &lt;- tibble(\n  isold = c(0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1),\n  y = c(1:6, 1:6),\n  count = c(174, 172, 104, 92, 41, 8, 46, 57, 66, 101, 154, 173)\n)\n\n\n\nExample rating data from Decarlo (2003)\n\n\nisold\ny\ncount\n\n\n\n\n0\n1\n174\n\n\n0\n2\n172\n\n\n0\n3\n104\n\n\n0\n4\n92\n\n\n0\n5\n41\n\n\n0\n6\n8\n\n\n1\n1\n46\n\n\n1\n2\n57\n\n\n1\n3\n66\n\n\n1\n4\n101\n\n\n1\n5\n154\n\n\n1\n6\n173\n\n\n\n\n\nHowever, we don’t need to summarise data to counts (or cell means, or the like), but can instead work with raw responses, as provided by the experimental program. Working with such trial-level data is especially useful when we wish to include covariates. Here is the data in the raw trial-level format:\n\n\nCode\nd &lt;- uncount(dsum, weights = count)\n\n\n\nExample rating data in raw format from Decarlo (2003)\n\n\nisold\ny\n\n\n\n\n0\n1\n\n\n0\n1\n\n\n0\n1\n\n\n0\n1\n\n\n0\n1\n\n\n0\n1\n\n\n\n\n\nWe can now proceed to fit the SDT models to this person’s data, beginning with the EVSDT model.\n\n\nEVSDT: one subject’s rating responses\nRecall that for the EVSDT model of binary responses, we modeled the probability p (of responding “old!” on trial i) as\n\\[p_i = \\Phi(d'\\mbox{isold}_i - c)\\]\nThis model gives the (z-scored) probability of responding “old” for new items (c = zFAR), and the increase (in z-scores) in “old” responses for old items (d’). For rating data, the model is similar but we now include multiple cs. These index the different criteria for responding with the different confidence ratings. The criteria are assumed to be ordered–people should be more lenient to say unsure old, vs. sure old, when the signal (memory strength) on that trial was weaker.\nThe EVSDT model for rating responses models the cumulative probability of responding with confidence rating k or less (\\(p(y_i \\leq k_i)\\); Decarlo (2003)):\n\\[p(y_i \\leq k_i) = \\Phi(d'\\mbox{isold}_i - c_{ki})\\]\nThis model is also known as an ordinal probit (\\(\\Phi\\)) model, and can be fit with widely available regression modeling software. (Decarlo 2003) showed how to use the PLUM procedure in SPSS to fit it for a single participant. However, we can obtain Bayesian inference for this model by estimating the model with the brms package in R (Bürkner 2017; Stan Development Team 2016b). Ignoring prior distributions for now, the brms syntax for estimating this model with the above data is:\n\n\nCode\nfit1 &lt;- brm(\n  y ~ isold,\n  family = cumulative(link = \"probit\"),\n  data = d,\n  cores = 4,\n  file = here(\"models/sdtmodel3-1\")\n)\n\n\nThis model estimates an intercept (criterion) for each response category, and the effect of isold, which is d’. The model’s posterior distribution is summarised below:\n\n\nCode\nsummary(fit1)\n#&gt;  Family: cumulative \n#&gt;   Links: mu = probit; disc = identity \n#&gt; Formula: y ~ isold \n#&gt;    Data: d (Number of observations: 1188) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept[1]    -1.07      0.05    -1.16    -0.98 1.00     3127     3037\n#&gt; Intercept[2]    -0.40      0.04    -0.48    -0.32 1.00     4601     3324\n#&gt; Intercept[3]     0.04      0.04    -0.03     0.12 1.00     4992     3310\n#&gt; Intercept[4]     0.57      0.04     0.49     0.66 1.00     4413     3400\n#&gt; Intercept[5]     1.25      0.05     1.16     1.35 1.00     4501     3203\n#&gt; isold1           1.26      0.07     1.12     1.38 1.00     3901     3138\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; disc     1.00      0.00     1.00     1.00   NA       NA       NA\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nThe five intercepts are the five criteria in the model, and isold is d’. I also estimated this model using SPSS, so it might be helpful to compare the results from these two approaches:\nPLUM y WITH x\n/CRITERIA=CIN(95) DELTA(0) LCONVERGE(0) MXITER(100) MXSTEP(5) PCONVERGE(1.0E-6) SINGULAR(1.0E-8)\n/LINK=PROBIT\n/PRINT=FIT KERNEL PARAMETER SUMMARY.\n\nParameter Estimates\n|-----------------|--------|----------|-----------------------------------|\n|                 |Estimate|Std. Error|95% Confidence Interval            |\n|                 |        |          |-----------------------|-----------|\n|                 |        |          |Lower Bound            |Upper Bound|\n|---------|-------|--------|----------|-----------------------|-----------|\n|Threshold|[y = 1]|-.442   |.051      |-.541                  |-.343      |\n|         |-------|--------|----------|-----------------------|-----------|\n|         |[y = 2]|.230    |.049      |.134                   |.326       |\n|         |-------|--------|----------|-----------------------|-----------|\n|         |[y = 3]|.669    |.051      |.569                   |.769       |\n|         |-------|--------|----------|-----------------------|-----------|\n|         |[y = 4]|1.198   |.056      |1.088                  |1.308      |\n|         |-------|--------|----------|-----------------------|-----------|\n|         |[y = 5]|1.876   |.066      |1.747                  |2.005      |\n|---------|-------|--------|----------|-----------------------|-----------|\n|Location |x      |1.253   |.065      |1.125                  |1.381      |\n|-------------------------------------------------------------------------|\nLink function: Probit.\nUnsurprisingly, the numerical results from brms (posterior means and standard deviations, credibility intervals) match the frequentist ones obtained from SPSS under these conditions.\nWe can now illustrate graphically how the estimated parameters map to the signal detection model. d’ is the separation of the signal and noise distributions’ peaks: It indexes the subject’s ability to discriminate signal from noise trials. The five intercepts are the (z-scored) criteria for responding with the different confidence ratings. If we convert the z-scores to proportions (using R’s pnorm() for example), they measure the (cumulative) area under the noise distribution to the left of that z-score. The model is visualized in Figure 6.\n\n\n\n\n\n\n\n\nFigure 6: The equal variance Gaussian signal detection model, visualized from the parameters’ posterior means. The two distributions are the noise distribution (dashed) and the signal distribution (solid). Dotted vertical lines are response criteria. d’ is the distance between the peaks of the two distributions.\n\n\n\n\n\n\n\nUVSDT: one subject’s rating responses\nNotice that the above model assumed that the noise and signal distributions have the same variance. The unequal variances SDT (UVSDT) model allows the signal distribution to have a different variance than the noise distribution (whose standard deviation is still arbitrarily fixed at 1). It has been found that when the signal distribution’s standard deviation is allowed to vary, it is consistently greater than 1.\nThe UVSDT model adds one parameter, and we can write out the resulting model by including the signal distribution’s standard deviation as a scale parameter in the above equation (Decarlo 2003). However, because the standard deviation parameter must be greater than zero, it is convenient to model \\(\\mbox{log}(\\sigma_{old}) = a\\) instead:\n\\[p(y_i \\leq k_i) = \\Phi(\\frac{d'\\mbox{isold}_i - c_k}{\\mbox{exp}(a\\mbox{isold}_i)})\\]\nIt turns out that this nonlinear model—also knows as a probit model with heteroscedastic error (e.g. DeCarlo (2010))—can be estimated with brms. Initially, I thought that we could write out a nonlinear brms formula for the ordinal probit model, but brms does not support nonlinear cumulative ordinal models. I then proceeded to modify the raw Stan code to estimate this model, but although that worked, it would be less practical for applied work because not everyone wants to go through the trouble of writing Stan code.\nAfter some back and forth with the creator of brms—Paul Bürkner, who deserves a gold medal for his continuing hard work on this free and open-source software—I found out that brms by default includes a similar parameter in ordinal regression models. If you scroll back up and look at the summary of fit1, at the top you will see that the model’s formula is:\nFormula: y ~ isold \ndisc = 1\nIn other words, there is a “discrimination” parameter disc, which is set to 1 by default. Here’s how brms parameterizes the ordinal probit model:\n\\[p(y_i \\leq k_i) = \\Phi(disc * (c_{ki} - d'\\mbox{isold}_i))\\]\nImportantly, we can also include predictors on disc. In this case, we want to estimate disc when isold is 1, such that disc is 1 for new items, but estimated from data for old items. This parameter is by default modelled through a log link function, and including a 0/1 predictor (isold) will therefore work fine:\n\\[p(y_i \\leq k_i) = \\Phi(\\mbox{exp}(disc\\mbox{isold}_i) * (c_{ki} - d'\\mbox{isold}_i))\\]\nWe can therefore estimate this model with only a small tweak to the EVSDT model’s code:\n\n\nCode\nuvsdt_m &lt;- bf(y ~ isold, disc ~ 0 + isold, cmc = FALSE)\n\n\nThere are two brms formulas in the model. The first, y ~ isold is already familiar to us. In the second formula, we write disc ~ 0 + isold to prevent the parameter from being estimated for the noise distribution: Recall that we have set the standard deviation of the noise distribution to be one (achieved by \\(exp(disc * \\mbox{0}) = 1\\)). In R’s (and by extension, brms’) modeling syntax 0 + ... means removing the intercept from the model. cmc = FALSE is needed. By including isold only, we achieve the 0/1 predictor as described above. We can then estimate the model:\n\n\nCode\nfit2 &lt;- brm(\n  uvsdt_m,\n  family = cumulative(link = \"probit\"),\n  data = d,\n  control = list(adapt_delta = .99),\n  file = here(\"models/sdtmodel3-2\")\n)\n\n\nThe model’s estimated parameters:\n\n\nCode\nsummary(fit2)\n#&gt;  Family: cumulative \n#&gt;   Links: mu = probit; disc = log \n#&gt; Formula: y ~ isold \n#&gt;          disc ~ 0 + isold\n#&gt;    Data: d (Number of observations: 1188) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept[1]    -0.54      0.05    -0.64    -0.43 1.00     2782     2584\n#&gt; Intercept[2]     0.20      0.05     0.11     0.30 1.00     4947     3515\n#&gt; Intercept[3]     0.71      0.05     0.61     0.82 1.00     4493     3393\n#&gt; Intercept[4]     1.37      0.07     1.25     1.50 1.00     2685     2943\n#&gt; Intercept[5]     2.31      0.11     2.10     2.54 1.00     1642     2005\n#&gt; isold            1.53      0.10     1.35     1.72 1.00     1855     2250\n#&gt; disc_isold      -0.36      0.06    -0.48    -0.24 1.00     1721     2213\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nNotice that we need to flip the sign of the disc parameter to get \\(\\mbox{log}(\\sigma_{old})\\). Exponentiation gives us the standard deviation of the signal distribution, and because we estimated the model in the Bayesian framework, our estimate of this parameter is a posterior distribution, plotted on the y-axis of Figure 7.\n\n\n\n\n\n\n\n\nFigure 7: The (approximate) joint posterior density of two UVSDT parameters (d’ and standard deviation of the signal distribution) fitted to one participant’s data. Lighter yellow colors indicate higher posterior density. Red point shows the maximum likelihood estimates obtained from SPSS’s ordinal regression module.\n\n\n\n\n\nWe can also compare the results from brms’ to ones obtained from SPSS (SPSS procedure described in (Decarlo 2003)):\nPLUM y WITH x\n/CRITERIA=CIN(95) DELTA(0) LCONVERGE(0) MXITER(100) MXSTEP(5) PCONVERGE(1.0E-6) SINGULAR(1.0E-8)\n/LINK=PROBIT\n/PRINT=FIT KERNEL PARAMETER SUMMARY\n/SCALE=x .\n\nParameter Estimates\n|-----------------|--------|----------|-----------------------------------|\n|                 |Estimate|Std. Error|95% Confidence Interval            |\n|                 |        |          |-----------------------|-----------|\n|                 |        |          |Lower Bound            |Upper Bound|\n|---------|-------|--------|----------|-----------------------|-----------|\n|Threshold|[y = 1]|-.533   |.054      |-.638                  |-.428      |\n|         |-------|--------|----------|-----------------------|-----------|\n|         |[y = 2]|.204    |.050      |.107                   |.301       |\n|         |-------|--------|----------|-----------------------|-----------|\n|         |[y = 3]|.710    |.053      |.607                   |.813       |\n|         |-------|--------|----------|-----------------------|-----------|\n|         |[y = 4]|1.366   |.067      |1.235                  |1.498      |\n|         |-------|--------|----------|-----------------------|-----------|\n|         |[y = 5]|2.294   |.113      |2.072                  |2.516      |\n|---------|-------|--------|----------|-----------------------|-----------|\n|Location |x      |1.519   |.096      |1.331                  |1.707      |\n|---------|-------|--------|----------|-----------------------|-----------|\n|Scale    |x      |.348    |.063      |.225                   |.472       |\n|-------------------------------------------------------------------------|\nLink function: Probit.\nAgain, the maximum likelihood estimates (SPSS) match our Bayesian quantities numerically, because we used uninformative prior distributions. Plotting the model’s implied distributions illustrates that the signal distribution has greater variance than the noise distribution (Figure 8).\n\n\n\n\n\n\n\n\nFigure 8: The unequal variance Gaussian signal detection model, visualized from the parameters’ posterior means. The two distributions are the noise distribution (dashed) and the signal distribution (solid). Dotted vertical lines are response criteria. d’ is the scaled distance between the peaks of the two distributions.\n\n\n\n\n\nAdditional quantities of interest can be calculated from the parameters’ posterior distributions. One benefit of obtaining samples from the posterior is that if we complete these calculations row-wise, we automatically obtain (samples from) the posterior distributions of these additional quantities.\nHere, we calculate one such quantity: The ratio of the noise to signal standard deviations (\\(\\mbox{exp}(-a)\\); notice that our model returns -a as disc_isold), which is also the slope of the z-ROC curve. We’ll first obtain the posterior samples of disc_isold, then calculate the ratio, and summarize the samples from ratio’s posterior distribution with their 2.5%, 50%, and 97.5%iles:\n\n\nCode\nas.data.frame(fit2, pars = \"b_disc_isold\") |&gt;\n  transmute(ratio = exp(b_disc_isold)) |&gt;\n  pull(ratio) |&gt;\n  quantile(probs = c(.025, .5, .975))\n#&gt;  2.5%   50% 97.5% \n#&gt;  0.62  0.70  0.79\n\n\nThese summaries are the parameter’s 95% Credible interval and median, and as such can be used to summarize this quantity in a publication. We could also visualize the posterior draws as a histogram:\n\n\nCode\nas.data.frame(fit2, pars = \"b_disc_isold\") |&gt;\n  transmute(ratio = exp(b_disc_isold)) |&gt;\n  ggplot(aes(ratio)) +\n  geom_histogram(col = \"black\", fill = \"gray70\") +\n  scale_y_continuous(expand = expansion(c(0, .1))) +\n  theme(aspect.ratio = 1)"
  },
  {
    "objectID": "modules/sdt/index.html#uvsdt-for-multiple-participants",
    "href": "modules/sdt/index.html#uvsdt-for-multiple-participants",
    "title": "Signal Detection Models",
    "section": "UVSDT for multiple participants",
    "text": "UVSDT for multiple participants\nAbove, we fit the UVSDT model for a single subject. However, we almost always want to discuss our inference about the population, not individual subjects. Further, if we wish to discuss individual subjects, we should place them in the context of other subjects. A multilevel (aka hierarchical, mixed) model accomplishes these goals by including population- and subject-level parameters.\n\nExample data set\nWe’ll use a data set of 48 subjects’ confidence ratings on a 6 point scale: 1 = “sure new”, …, 6 = “sure old” (Koen et al. 2013). This data set is included in the R package MPTinR (Singmann and Kellen 2013).\nIn this experiment (Koen et al. 2013), participants completed a study phase, and were then tested under full attention, or while doing a second task. Here, we focus on the rating data provided in the full attention condition. Below, I reproduce the aggregate rating counts for old and new items from the Table in the article’s appendix. (It is useful to ensure that we are indeed using the same data.)\n\n\n\nExample data from Koen et al. (2013)\n\n\nisold\n6\n5\n4\n3\n2\n1\n\n\n\n\nold\n2604\n634\n384\n389\n422\n309\n\n\nnew\n379\n356\n454\n871\n1335\n1365\n\n\n\n\n\nFor complete R code, including pre-processing the data, please refer to the source code of this blog post. I have omitted some of the less important code from the blog post for clarity.\n\n\nModel syntax\nHere’s the brms syntax we used for estimating the model for a single participant:\n\n\nCode\nuvsdt_m &lt;- bf(y ~ isold, disc ~ 0 + isold, cmc = FALSE)\n\n\nWith the above syntax we specifed seven parameters: Five intercepts (aka ‘thresholds’ in the cumulative probit model) on y5; the effect of isold on y; and the effect of isold on the discrimination parameter disc6. There are five intercepts (thresholds), because there are six response categories.\nWe extend the code to a hierarchical model by specifying that all these parameters vary across participants (variable id in the data).\n\n\nCode\nuvsdt_h &lt;- bf(\n  y ~ isold + (isold | s | id),\n  disc ~ 0 + isold + (0 + isold | s | id),\n  cmc = FALSE\n)\n\n\nRecall from above that using |s| leads to estimating correlations among the varying effects. There will only be one standard deviation associated with the thresholds; that is, the model assumes that subjects vary around the mean threshold similarly for all thresholds.\n\n\nPrior distributions\nI set a N(1, 3) prior on dprime, just because I know that in these tasks performance is usually pretty good. Perhaps this prior is also influenced by my reading of the paper! I also set a N(0, 1) prior on a: Usually this parameter is found to be around \\(-\\frac{1}{4}\\), but I’m ignoring that information.\nThe t(7, 0, .33) priors on the between-subject standard deviations reflect my assumption that the subjects should be moderately similar to one another, but also allows larger deviations. (They are t-distributions with seven degrees of freedom, zero mean, and .33 standard deviation.)\n\n\nCode\nPrior &lt;- c(\n  prior(normal(1, 3), class = \"b\", coef = \"isold\"),\n  prior(normal(0, 1), class = \"b\", coef = \"isold\", dpar = \"disc\"),\n  prior(student_t(7, 0, .33), class = \"sd\"),\n  prior(student_t(7, 0, .33), class = \"sd\", dpar = \"disc\"),\n  prior(lkj(2), class = \"cor\")\n)\n\n\n\n\nEstimate and summarise parameters\nWe can then estimate the model as before. Be aware that this model takes quite a bit longer to estimate, so for this example I have set only 500 HMC iterations.\n\n\nCode\nfit &lt;- brm(uvsdt_h,\n           family = cumulative(link = \"probit\"),\n           data = d,\n           prior = Prior,\n           control = list(adapt_delta = .9), \n           init = 0,\n           iter = 500,\n           file = here(\"models/sdtmodel4-1\")\n)\n\n\nWe then display numerical summaries of the model’s parameters. Note that the effective sample sizes are modest, and Rhats indicate that we would benefit from drawing more samples from the posterior. For real applications, I recommend more than 500 iterations per chain.\n\n\nCode\nsummary(fit)\n#&gt;  Family: cumulative \n#&gt;   Links: mu = probit; disc = log \n#&gt; Formula: y ~ isold + (isold | s | id) \n#&gt;          disc ~ 0 + isold + (0 + isold | s | id)\n#&gt;    Data: d (Number of observations: 9502) \n#&gt;   Draws: 4 chains, each with iter = 500; warmup = 250; thin = 1;\n#&gt;          total post-warmup draws = 1000\n#&gt; \n#&gt; Multilevel Hyperparameters:\n#&gt; ~id (Number of levels: 48) \n#&gt;                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sd(Intercept)                 0.34      0.04     0.28     0.43 1.00      264      418\n#&gt; sd(isold)                     0.78      0.10     0.61     0.99 1.01      191      443\n#&gt; sd(disc_isold)                0.46      0.05     0.37     0.56 1.02      233      477\n#&gt; cor(Intercept,isold)         -0.47      0.12    -0.68    -0.21 1.04      205      325\n#&gt; cor(Intercept,disc_isold)     0.34      0.13     0.08     0.57 1.02      220      389\n#&gt; cor(isold,disc_isold)        -0.76      0.08    -0.87    -0.57 1.02      204      411\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept[1]    -0.60      0.05    -0.69    -0.50 1.02      149      251\n#&gt; Intercept[2]     0.20      0.05     0.10     0.30 1.02      162      208\n#&gt; Intercept[3]     0.70      0.05     0.60     0.80 1.02      169      227\n#&gt; Intercept[4]     1.04      0.05     0.94     1.15 1.02      176      262\n#&gt; Intercept[5]     1.49      0.05     1.38     1.60 1.02      188      310\n#&gt; isold            1.86      0.12     1.65     2.12 1.02      156      250\n#&gt; disc_isold      -0.38      0.07    -0.54    -0.24 1.01      186      308\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nLet’s first focus on the “Population-level Effects”: The effects for the “average person”. isold is d’, and is very close to the one reported in the paper (eyeballing Figure 3 in Koen et al. (2013); this d’ is not numerically reported in the paper). disc_isold is, because of the model’s parameterization, \\(-\\mbox{log}(\\sigma_{signal}) = -a\\). The paper discusses \\(V_o = \\sigma_{signal}\\), and therefore we transform each posterior sample of our -a to obtain samples from \\(V_o\\)’s posterior distribution.\n\n\nCode\nsamples &lt;- posterior_samples(fit, \"b_\") |&gt;\n  mutate(Vo = exp(-b_disc_isold))\n\n\nWe can then plot density curves (Gabry 2017) for each of the Population-level Effects in our model, including \\(V_o\\). Figure 9 shows that our estimate of \\(V_o\\) corresponds very closely to the one reported in the paper (Figure 3 in Koen et al. (2013)).\n\n\nCode\nmcmc_areas(samples, point_est = \"mean\", prob = .8)\n\n\n\n\n\n\n\n\nFigure 9: Density plots of UVSDT model’s Population-level Effects’ posterior distributions. Different parameters are indicated on the y-axis, and possible values on the x-axis. Vertical lines are posterior means, and shaded areas are 80% credible intervals.\n\n\n\n\n\n\nHeterogeneity parameters\nAlthough the “population-level estimates”, which perhaps should be called “average effects”, are usually the main target of inference, they are not the whole story, nor are they necessarily the most interesting part of it. It has been firmly established that, when allowed to vary, the standard deviation of the signal distribution is greater than 1. However, the between-subject variability of this parameter has received less interest. Figure 10 reveals that the between-subject heterogeneity of a is quite large: The subject-specific effects have a standard deviation around .5.\n\n\nCode\nsamples_h &lt;- posterior_samples(fit, c(\"sd_\", \"cor_\"))\nmcmc_areas(samples_h, point_est = \"mean\", prob = .8)\n\n\n\n\n\n\n\n\nFigure 10: Density plots of the standard deviation and correlation parameters of the UVSDT model’s parameters. Parameter’s appended with ’sd_id__’ are between-id standard deviations, ones with ’cor_id__’ are between-id correlations.\n\n\n\n\n\nFigure 10 also tells us that the subject-specific d’s and as are correlated (“cor_id__isold__disc_isold”).\n\n\n\n\n\n\n\n\nFigure 11: Scatterplot of posterior means of subject-specific d-primes and signal distribution standard deviations."
  },
  {
    "objectID": "modules/sdt/index.html#conclusion",
    "href": "modules/sdt/index.html#conclusion",
    "title": "Signal Detection Models",
    "section": "Conclusion",
    "text": "Conclusion\nEstimating EVSDT and UVSDT models in the Bayesian framework with the brms package (Bürkner 2017) is both easy (relatively speaking) and informative. In this post, we estimated a hierarchical nonlinear cognitive model using no more than a few lines of code. Previous literature on the topic (e.g. Rouder et al. (2007)) has focused on simpler (EVSDT) models with more complicated implementations–hopefully in this post I have shown that these models are within the reach of a greater audience, provided that they have some familiarity with R.\nAnother point worth making is a more general one about hierarchical models: We know that participants introduce (random) variation in our models. Ignoring this variation is clearly not good (Estes 1956). It is more appropriate to model this variability, and use the resulting parameters to draw inference about the heterogeneity in parameters (and more generally, cognitive strategies) across individuals. Although maximum likelihood methods provide (noisy) point estimates of what I’ve here called between-subject heterogeneity parameters, the Bayesian method allows drawing firm conclusions about these parameters."
  },
  {
    "objectID": "modules/sdt/index.html#footnotes",
    "href": "modules/sdt/index.html#footnotes",
    "title": "Signal Detection Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAn earlier version of this write-up used the negative standardized false alarm rate -zFAR in line with (DeCarlo 1998), but that is not a standard definition of a criterion. (Thanks to Filip and Mike for pointing this out.)↩︎\nYou are probably familiar with logistic regression models, which are just another binary GLM, but with the logistic link function!↩︎\nHierarchical regression is sometimes used to mean the practice of adding predictors to a regression model based on the predictors’ p-values. Whatever you do, don’t do that.↩︎\nThe label “Group-Level Effects” might be slightly confusing because the SD and correlation parameters describe the population of subject-specific effects. I have yet to find a 100% satisfactory terminology here, but think that brms’ terminology is certainly less confusing than that of “random” and “fixed” effects, traditionally encountered in multilevel modeling literature.↩︎\nRecall that intercepts are automatically included, but can be explicitly included by adding 1 to the formula’s right hand side.↩︎\n0 + ... removes the model’s intercept.↩︎"
  }
]